{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "keras_medicine.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "PRZkKs_FB66i",
        "SEdPqiD-krvg"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mrkevinlin/MLmed/blob/master/keras_medicine.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "vs7O6ODuZKs8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Notes:\n",
        "#**- Determine imputation to use**"
      ]
    },
    {
      "metadata": {
        "id": "Npz1MpjiJHfR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Initialize everything**"
      ]
    },
    {
      "metadata": {
        "id": "Ajb6OoyEoOsp",
        "colab_type": "code",
        "outputId": "79d21013-cc1c-4457-8d31-75181d1f26ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install --upgrade -q gspread\n",
        "\n",
        "from __future__ import print_function\n",
        "\n",
        "import math\n",
        "from google.colab import files\n",
        "from IPython import display\n",
        "from matplotlib import cm\n",
        "from matplotlib import gridspec\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn.metrics as metrics\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow import keras \n",
        "from keras.wrappers.scikit_learn import KerasRegressor\n",
        "\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "pd.options.display.max_rows = 15\n",
        "pd.options.display.max_columns = 40\n",
        "pd.options.display.float_format = '{:.3f}'.format"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "havMoLwBoU8X",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "import gspread\n",
        "from oauth2client.client import GoogleCredentials\n",
        "gc = gspread.authorize(GoogleCredentials.get_application_default())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oV1GAFHjJO3c",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Create a DataFrame of patient data"
      ]
    },
    {
      "metadata": {
        "id": "3fuIiFwBB3-G",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Import CSV to populate a DataFrame**"
      ]
    },
    {
      "metadata": {
        "id": "KkpYbCCzBvjV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Open Google Sheet of patient data and get column titles\n",
        "patient_dataframe = gc.open('patient_data').sheet1\n",
        "column_names = patient_dataframe.row_values(1)\n",
        "\n",
        "# Process Google Sheet into a pandas dataframe of all numeric values\n",
        "patient_dataframe = pd.DataFrame.from_records(\n",
        "    patient_dataframe.get_all_values(),\n",
        "    columns=column_names)\n",
        "patient_dataframe = patient_dataframe.iloc[1:]\n",
        "patient_dataframe = patient_dataframe.apply(pd.to_numeric, errors='coerce')\n",
        "patient_dataframe = patient_dataframe.replace('', np.nan)\n",
        "patient_dataframe_original = patient_dataframe.copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PRZkKs_FB66i",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "# **View some stats on the data**"
      ]
    },
    {
      "metadata": {
        "id": "VP1GM_Y5B_Aq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def view_stats(df):\n",
        "  plt.close('all')\n",
        "  display.display(df.describe())\n",
        "  print(\"\\nNumber missing in each column:\")\n",
        "  display.display(df.isna().sum())\n",
        "\n",
        "  plt.close('all')\n",
        "  for col in df.columns:\n",
        "    plt.figure()\n",
        "    plt.hist(df[col])\n",
        "    plt.xlabel(col)\n",
        "    plt.ylabel(\"Count\")\n",
        "\n",
        "view_stats(patient_dataframe)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oFh4r7LGPUkQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Split into training and test sets**"
      ]
    },
    {
      "metadata": {
        "id": "NFmmjo69PavB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Close the matlib plots from view stats to reduce memory usage\n",
        "plt.close('all')\n",
        "# Reset the dataframe\n",
        "patient_dataframe = patient_dataframe_original.copy()\n",
        "\n",
        "# Set random number seed\n",
        "rand_state = 4\n",
        "\n",
        "# Randomize and divide the data set into training and test sets\n",
        "train_dataframe = patient_dataframe.sample(frac=0.8, random_state=rand_state)\n",
        "test_dataframe = patient_dataframe.drop(train_dataframe.index)\n",
        "\n",
        "#test_dataframe.describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UiVC8iUcIIXN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Create methods for cleaning up data**"
      ]
    },
    {
      "metadata": {
        "id": "JtwnMn_HHnNm",
        "colab_type": "code",
        "outputId": "45a23f9d-e6f9-4872-cbf8-2a846129fdbe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        }
      },
      "cell_type": "code",
      "source": [
        "def process_data(df):\n",
        "  # Try alternate features and targets\n",
        "  trial = 2\n",
        "  \n",
        "  # Specify features and labels to work with\n",
        "  if trial==1: # Predict improvement in 6MWT distance after CR\n",
        "    target_label = 'delta_6mwt'\n",
        "    numeric_selected_features = ['entry_knowledge', 'entry_height', 'entry_weight', 'entry_waist', 'entry_BF', 'entry_BMI', 'entry_met']\n",
        "    optional_numeric_selected_features = ['entry_chol', 'entry_trig', 'entry_hdl', 'entry_ldl']\n",
        "    categorical_selected_features = ['normal_a', 'borderline_a', 'anxiety', 'normal_d', 'borderline_d', 'depression']\n",
        "    \n",
        "    df = create_synthetic_target(df, target_label)\n",
        "    \n",
        "  elif trial==2: # Predict initial exercise tolerance with entry MET\n",
        "    target_label = 'entry_met'\n",
        "    numeric_selected_features = ['entry_knowledge', 'entry_height', 'entry_weight', 'entry_waist', 'entry_BF', 'entry_BMI', 'entry_6mwt']\n",
        "    optional_numeric_selected_features = ['entry_chol', 'entry_trig', 'entry_hdl', 'entry_ldl']\n",
        "    categorical_selected_features = ['normal_a', 'borderline_a', 'anxiety', 'normal_d', 'borderline_d', 'depression']\n",
        "      \n",
        "  else:\n",
        "    return\n",
        "  \n",
        "  df = create_features(df)\n",
        "  df = clean_up_by_target(df, target_label)\n",
        "  df = remove_outliers(df, 'entry_trig', 1000)\n",
        "  df = remove_outliers(df, 'entry_6mwt', 2000)\n",
        "  df = median_impute_missing_values(df) # Temporary  \n",
        "  df[numeric_selected_features] = scale_features_z_score(df[numeric_selected_features].copy())\n",
        "  \n",
        "  # Split into used feature and label dataframes\n",
        "  feature_df = df[numeric_selected_features+categorical_selected_features]\n",
        "  target_df = df[target_label]\n",
        "  \n",
        "  return feature_df, target_df\n",
        "\n",
        "# Create synthetic features\n",
        "def create_features(df):\n",
        "  df = calculate_bmi(df)\n",
        "  df = create_hads_bins(df)\n",
        "  return df\n",
        "\n",
        "# Create target label of change in 6MWT results  \n",
        "def create_synthetic_target(df, target):\n",
        "  df[target] = (df['exit_6mwt'] - df['entry_6mwt'])\n",
        "  return df\n",
        "  \n",
        "# Create categorical bins of anxiety and depression scale\n",
        "def create_hads_bins(df):\n",
        "  hads_bins=[0,7,10,21]\n",
        "  anxiety_df = pd.get_dummies(pd.cut(df['entry_hads_a'], bins=hads_bins, labels=['normal_a', 'borderline_a', 'anxiety']))\n",
        "  depression_df = pd.get_dummies(pd.cut(df['entry_hads_d'], bins=hads_bins, labels=['normal_d', 'borderline_d', 'depression']))\n",
        "  return df.join(anxiety_df).join(depression_df) \n",
        "  \n",
        "# Recalculate and fill in BMI from height/weight\n",
        "def calculate_bmi(df):\n",
        "  df['calc_bmi'] = (702.95 * df['entry_weight']/(df['entry_height'] ** 2))\n",
        "  return df\n",
        "\n",
        "# Remove all rows with values missing in the specified columns\n",
        "def clean_up_by_target(df, column):\n",
        "  return df.dropna(subset=[column])\n",
        "\n",
        "# Remove flagrant outliers by clipping\n",
        "def remove_outliers(df, feature, maximum):\n",
        "  df[feature] = df[feature].clip(lower=0, upper=maximum)\n",
        "  return df\n",
        "\n",
        "# Replace missing values with the median of the group (temporary measure)\n",
        "def median_impute_missing_values(df):\n",
        "  for col in df.columns:\n",
        "    if df[col].isnull().values.any():\n",
        "      df[col] = df[col].fillna(df[col].median())\n",
        "  return df\n",
        "\n",
        "# Normalize the values of features\n",
        "def scale_features_z_score(df):\n",
        "  for col in df.columns:\n",
        "    df[col] = (df[col] - df[col].mean())/df[col].std()\n",
        "  return df\n",
        "  \n",
        "feature_dataframe, target_dataframe = process_data(train_dataframe)\n",
        "display.display(feature_dataframe.describe())\n",
        "display.display(target_dataframe.describe())"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>entry_knowledge</th>\n",
              "      <th>entry_height</th>\n",
              "      <th>entry_weight</th>\n",
              "      <th>entry_waist</th>\n",
              "      <th>entry_BF</th>\n",
              "      <th>entry_BMI</th>\n",
              "      <th>entry_6mwt</th>\n",
              "      <th>normal_a</th>\n",
              "      <th>borderline_a</th>\n",
              "      <th>anxiety</th>\n",
              "      <th>normal_d</th>\n",
              "      <th>borderline_d</th>\n",
              "      <th>depression</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>395.000</td>\n",
              "      <td>395.000</td>\n",
              "      <td>395.000</td>\n",
              "      <td>395.000</td>\n",
              "      <td>395.000</td>\n",
              "      <td>395.000</td>\n",
              "      <td>395.000</td>\n",
              "      <td>395.000</td>\n",
              "      <td>395.000</td>\n",
              "      <td>395.000</td>\n",
              "      <td>395.000</td>\n",
              "      <td>395.000</td>\n",
              "      <td>395.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>-0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>-0.000</td>\n",
              "      <td>-0.000</td>\n",
              "      <td>-0.000</td>\n",
              "      <td>-0.000</td>\n",
              "      <td>0.544</td>\n",
              "      <td>0.116</td>\n",
              "      <td>0.114</td>\n",
              "      <td>0.524</td>\n",
              "      <td>0.106</td>\n",
              "      <td>0.099</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.499</td>\n",
              "      <td>0.321</td>\n",
              "      <td>0.318</td>\n",
              "      <td>0.500</td>\n",
              "      <td>0.309</td>\n",
              "      <td>0.299</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>-3.421</td>\n",
              "      <td>-3.088</td>\n",
              "      <td>-2.097</td>\n",
              "      <td>-2.586</td>\n",
              "      <td>-2.515</td>\n",
              "      <td>-2.151</td>\n",
              "      <td>-3.060</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>-0.709</td>\n",
              "      <td>-0.397</td>\n",
              "      <td>-0.701</td>\n",
              "      <td>-0.667</td>\n",
              "      <td>-0.754</td>\n",
              "      <td>-0.600</td>\n",
              "      <td>-0.427</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.044</td>\n",
              "      <td>-0.022</td>\n",
              "      <td>-0.164</td>\n",
              "      <td>-0.084</td>\n",
              "      <td>-0.084</td>\n",
              "      <td>-0.154</td>\n",
              "      <td>0.065</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.848</td>\n",
              "      <td>0.604</td>\n",
              "      <td>0.551</td>\n",
              "      <td>0.584</td>\n",
              "      <td>0.719</td>\n",
              "      <td>0.506</td>\n",
              "      <td>0.527</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.601</td>\n",
              "      <td>3.106</td>\n",
              "      <td>4.189</td>\n",
              "      <td>4.170</td>\n",
              "      <td>2.512</td>\n",
              "      <td>5.278</td>\n",
              "      <td>3.342</td>\n",
              "      <td>1.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>1.000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       entry_knowledge  entry_height  entry_weight  entry_waist  entry_BF  \\\n",
              "count          395.000       395.000       395.000      395.000   395.000   \n",
              "mean            -0.000         0.000         0.000       -0.000    -0.000   \n",
              "std              1.000         1.000         1.000        1.000     1.000   \n",
              "min             -3.421        -3.088        -2.097       -2.586    -2.515   \n",
              "25%             -0.709        -0.397        -0.701       -0.667    -0.754   \n",
              "50%              0.044        -0.022        -0.164       -0.084    -0.084   \n",
              "75%              0.848         0.604         0.551        0.584     0.719   \n",
              "max              1.601         3.106         4.189        4.170     2.512   \n",
              "\n",
              "       entry_BMI  entry_6mwt  normal_a  borderline_a  anxiety  normal_d  \\\n",
              "count    395.000     395.000   395.000       395.000  395.000   395.000   \n",
              "mean      -0.000      -0.000     0.544         0.116    0.114     0.524   \n",
              "std        1.000       1.000     0.499         0.321    0.318     0.500   \n",
              "min       -2.151      -3.060     0.000         0.000    0.000     0.000   \n",
              "25%       -0.600      -0.427     0.000         0.000    0.000     0.000   \n",
              "50%       -0.154       0.065     1.000         0.000    0.000     1.000   \n",
              "75%        0.506       0.527     1.000         0.000    0.000     1.000   \n",
              "max        5.278       3.342     1.000         1.000    1.000     1.000   \n",
              "\n",
              "       borderline_d  depression  \n",
              "count       395.000     395.000  \n",
              "mean          0.106       0.099  \n",
              "std           0.309       0.299  \n",
              "min           0.000       0.000  \n",
              "25%           0.000       0.000  \n",
              "50%           0.000       0.000  \n",
              "75%           0.000       0.000  \n",
              "max           1.000       1.000  "
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "count   395.000\n",
              "mean      2.543\n",
              "std       0.477\n",
              "min       1.100\n",
              "25%       2.300\n",
              "50%       2.600\n",
              "75%       2.900\n",
              "max       4.400\n",
              "Name: entry_met, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "lo76Dp4J6NJO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Determine correlations between features and target to find best features to use\n",
        "\n",
        "#correlation_dataframe = feature_dataframe.copy()\n",
        "#correlation_dataframe[\"target\"] = target_dataframe[\"delta_6mwt\"]\n",
        "#correlation_dataframe.corr()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SEdPqiD-krvg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Old, working standalone cross validation**"
      ]
    },
    {
      "metadata": {
        "id": "Ea4ZMu1QkO_o",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def build_model(train_df):\n",
        "  model = keras.Sequential([\n",
        "      layers.Dense(100, kernel_regularizer=keras.regularizers.l1(0.001), activation=tf.nn.relu, input_shape=[len(train_df.columns)]),\n",
        "      layers.Dropout(0.5),\n",
        "      layers.Dense(100, kernel_regularizer=keras.regularizers.l1(0.001), activation=tf.nn.relu),\n",
        "      layers.Dropout(0.5),\n",
        "      layers.Dense(100, kernel_regularizer=keras.regularizers.l1(0.001), activation=tf.nn.relu),\n",
        "      layers.Dense(1)\n",
        "  ])\n",
        "  \n",
        "  optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
        "  \n",
        "  model.compile(loss='mse',\n",
        "               optimizer=optimizer,\n",
        "               metrics=['mae', 'mse'])\n",
        "  return model\n",
        "\n",
        "# Train and evaluate the model\n",
        "def train_model(model, x_train, y_train, x_test, y_test, early_stop):\n",
        "  if(early_stop):\n",
        "    hist = model.fit(\n",
        "        x = x_train, \n",
        "        y = y_train,\n",
        "        epochs = EPOCHS,\n",
        "        verbose=1,\n",
        "        callbacks = [early_stop_call],\n",
        "        validation_data = (x_test, y_test)\n",
        "    )\n",
        "  else:\n",
        "    hist = model.fit(\n",
        "        x = x_train, \n",
        "        y = y_train,\n",
        "        epochs = EPOCHS,\n",
        "        validation_data = (x_test, y_test)\n",
        "    )\n",
        "  return hist\n",
        "  \n",
        "# Stop training with no improvement\n",
        "early_stop_call = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
        "EPOCHS = 1000\n",
        "end_fold_error = pd.DataFrame(columns=['loss', 'MAE', 'MSE', 'test_loss', 'test_MAE', 'test_MSE'])\n",
        "  \n",
        "# Create cross validator\n",
        "kf = KFold(n_splits=10, shuffle=True, random_state=4)\n",
        "\n",
        "# Loop through the k folds for cross validation\n",
        "for i, (train_index, test_index) in enumerate(kf.split(train_dataframe), 1):\n",
        "  print(\"Training on fold \" + str(i))\n",
        "  \n",
        "  #feature_train, feature_test = feature_data.iloc[train_index].copy(), feature_data.iloc[test_index].copy()\n",
        "  #label_train, label_test = label_data.iloc[train_index], label_data.iloc[test_index]\n",
        "  \n",
        "  feature_train, label_train = process_data(train_dataframe.iloc[train_index].copy())\n",
        "  feature_test, label_test = process_data(train_dataframe.iloc[test_index].copy())\n",
        "  \n",
        "  model = None\n",
        "  model = build_model(feature_train)\n",
        "  \n",
        "  history = train_model(model, feature_train, label_train, feature_test, label_test, early_stop=True)\n",
        "  mse_history = history.history['mean_squared_error']\n",
        "  val_mse_history = history.history['val_mean_squared_error']\n",
        "  end_fold_error = end_fold_error.append(\n",
        "      pd.Series([history.history['loss'][-1],\n",
        "                 history.history['mean_absolute_error'][-1],\n",
        "                 mse_history[-1], \n",
        "                 history.history['val_loss'][-1],\n",
        "                 history.history['val_mean_absolute_error'][-1],\n",
        "                 val_mse_history[-1]], \n",
        "                index=end_fold_error.columns), ignore_index=True)\n",
        "  print(\"Last training error: \" + str(mse_history[-1]))\n",
        "  print(\"Last validation error: \" + str(val_mse_history[-1]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5KKOPverI-pT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Set up Keras TensorFlow code**"
      ]
    },
    {
      "metadata": {
        "id": "6pSrGMNc1cZD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Set up functions to build and train models**"
      ]
    },
    {
      "metadata": {
        "id": "J-r55SdN11Sp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "https://weina.me/nested-cross-validation/\n",
        "\n",
        "https://machinelearningmastery.com/grid-search-hyperparameters-deep-learning-models-python-keras/"
      ]
    },
    {
      "metadata": {
        "id": "R7wvPh1AI-Og",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Create a model with various hyperparameters default\n",
        "def build_model(learn_rate=0.001, neurons=1, dropout_rate=0.0):\n",
        "  model = keras.Sequential([\n",
        "      layers.Dense(neurons, activation=tf.nn.relu, input_shape=[len(feature_dataframe.columns)]),\n",
        "      layers.Dropout(dropout_rate),\n",
        "      layers.Dense(64, activation=tf.nn.relu),\n",
        "      layers.Dropout(dropout_rate),\n",
        "      layers.Dense(1)\n",
        "  ])\n",
        "  \n",
        "  optimizer = tf.keras.optimizers.RMSprop(lr=learn_rate)\n",
        "  \n",
        "  model.compile(loss='mse',\n",
        "               optimizer=optimizer,\n",
        "               metrics=['mae', 'mse'])\n",
        "  return model\n",
        "\n",
        "# Train and evaluate the model\n",
        "def train_model(model, x_train, y_train, x_test, y_test, epochs=100):\n",
        "  hist = model.fit(\n",
        "      x = x_train, \n",
        "      y = y_train,\n",
        "      epochs = epochs,\n",
        "      verbose=0,\n",
        "      callbacks = [early_stop_call],\n",
        "      validation_data = (x_test, y_test))\n",
        "  return hist\n",
        "  \n",
        "# Callback function to stop training with no improvement\n",
        "early_stop_call = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LYk2WmA6xeo8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Create nested cross-validation for optimal hyperparameter search and model performance estimation**"
      ]
    },
    {
      "metadata": {
        "id": "KKxhbC8k7OlA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "https://stackoverflow.com/questions/42228735/scikit-learn-gridsearchcv-with-multiple-repetitions/42230764#42230764\n",
        "https://scikit-learn.org/stable/auto_examples/model_selection/plot_nested_cross_validation_iris.html\n",
        "\n",
        "**Nested versus non-nested cross-validation JUPYTER NOTEBOOK**"
      ]
    },
    {
      "metadata": {
        "id": "WWD7m1PggnSw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Create cross validator\n",
        "errr = KFold(n_splits=3, shuffle=True, random_state=4)\n",
        "scoresss = []\n",
        "test_model = KerasRegressor(build_fn=build_model, neurons=64, dropout_rate=0.5, epochs=1000)\n",
        "\n",
        "scoresss = cross_val_score(test_model, X=feature_dataframe, y=target_dataframe, scoring='neg_mean_squared_error', cv=errr, verbose=0)\n",
        "\n",
        "display.display(scoresss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CinM9_pfRfkx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_mDvYhjK9mP8",
        "colab_type": "code",
        "outputId": "ec4c25a2-b14c-4712-b4a8-ea18a57be074",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3006
        }
      },
      "cell_type": "code",
      "source": [
        "outer_fold = KFold(n_splits=10, shuffle=True, random_state=rand_state)\n",
        "inner_fold = KFold(n_splits=2, shuffle=True, random_state=rand_state)\n",
        "\n",
        "outer_scores = np.zeros(10)\n",
        "inner_scores = []\n",
        "best_params = []\n",
        "\n",
        "learn_rate = [0.001, 0.01]#, 0.1, 0.25, 0.5]\n",
        "dropout_rate = [0.0, 0.5]#, 0.2, 0.4, 0.6, 0.8]\n",
        "neurons = [16, 64]#[1, 4, 16, 64]\n",
        "parameters = dict(#learn_rate=learn_rate,\n",
        "                    #dropout_rate=dropout_rate,\n",
        "                    neurons=neurons\n",
        "                 )\n",
        "\n",
        "inner_model = None\n",
        "inner_model = KerasRegressor(build_fn=build_model, epochs=1000, verbose=0)\n",
        "grid_estimator = GridSearchCV(estimator=inner_model, param_grid=parameters, scoring='neg_mean_squared_error', cv=inner_fold, verbose=2, iid=False)\n",
        "#outer_scores = cross_val_score(grid, X=feature_dataframe, y=target_dataframe, scoring='neg_mean_squared_error', cv=outer_fold, verbose=0)\n",
        "\n",
        "for i, (outer_train_index, outer_test_index) in enumerate(outer_fold.split(train_dataframe)):\n",
        "  \n",
        "  outer_x_train, outer_y_train = process_data(train_dataframe.iloc[outer_train_index].copy())\n",
        "  outer_x_test, outer_y_test = process_data(train_dataframe.iloc[outer_test_index].copy())\n",
        "  \n",
        "  grid_estimator.fit(outer_x_train, outer_y_train)\n",
        "  inner_scores.append(grid_estimator.score(outer_x_test, outer_y_test))\n",
        "  best_params.append(grid_estimator.best_params_)\n",
        "  print(inner_scores)\n",
        "  print(best_params)\n",
        "  \n",
        "outer_scores = outer_scores.append(inner_scores.mean())\n",
        "print(\"Overall score\")\n",
        "print(outer_scores)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n",
            "[CV] neurons=16 ......................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ....................................... neurons=16, total=  35.1s\n",
            "[CV] neurons=16 ......................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   35.1s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ....................................... neurons=16, total=  35.6s\n",
            "[CV] neurons=64 ......................................................\n",
            "[CV] ....................................... neurons=64, total=  36.1s\n",
            "[CV] neurons=64 ......................................................\n",
            "[CV] ....................................... neurons=64, total=  36.5s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  2.4min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[-0.08304153355234911]\n",
            "[{'neurons': 64}]\n",
            "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n",
            "[CV] neurons=16 ......................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ....................................... neurons=16, total=  37.3s\n",
            "[CV] neurons=16 ......................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   37.3s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ....................................... neurons=16, total=  38.3s\n",
            "[CV] neurons=64 ......................................................\n",
            "[CV] ....................................... neurons=64, total=  38.4s\n",
            "[CV] neurons=64 ......................................................\n",
            "[CV] ....................................... neurons=64, total=  39.0s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  2.5min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[-0.08304153355234911, -0.09355915295065181]\n",
            "[{'neurons': 64}, {'neurons': 16}]\n",
            "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n",
            "[CV] neurons=16 ......................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ....................................... neurons=16, total=  39.4s\n",
            "[CV] neurons=16 ......................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   39.5s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ....................................... neurons=16, total=  40.1s\n",
            "[CV] neurons=64 ......................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-1164f187b7f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m   \u001b[0mouter_x_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouter_y_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mouter_test_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m   \u001b[0mgrid_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouter_x_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouter_y_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m   \u001b[0minner_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrid_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouter_x_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouter_y_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m   \u001b[0mbest_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrid_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    720\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1189\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1191\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    709\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 711\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    712\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m                 \u001b[0mall_candidate_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    918\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 920\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    921\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    757\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    526\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    529\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/wrappers/scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0mfit_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m         \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    878\u001b[0m           \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m           \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m           validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, mode, validation_in_fit, **kwargs)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 329\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    330\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3071\u001b[0m         \u001b[0mfeed_symbols\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feed_symbols\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetches\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m \u001b[0;32mor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3072\u001b[0m         session != self._session):\n\u001b[0;32m-> 3073\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_arrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_symbols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3074\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3075\u001b[0m     fetched = self._callable_fn(*array_vals,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m_make_callable\u001b[0;34m(self, feed_arrays, feed_symbols, symbol_vals, session)\u001b[0m\n\u001b[1;32m   3017\u001b[0m       \u001b[0mcallable_opts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCopyFrom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3018\u001b[0m     \u001b[0;31m# Create callable.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3019\u001b[0;31m     \u001b[0mcallable_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_callable_from_options\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallable_opts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3020\u001b[0m     \u001b[0;31m# Cache parameters corresponding to the generated callable, so that\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3021\u001b[0m     \u001b[0;31m# we can detect future mismatches and refresh the callable.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_make_callable_from_options\u001b[0;34m(self, callable_options)\u001b[0m\n\u001b[1;32m   1469\u001b[0m     \"\"\"\n\u001b[1;32m   1470\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1471\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mBaseSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallable_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1472\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, session, callable_options)\u001b[0m\n\u001b[1;32m   1423\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1424\u001b[0m           self._handle = tf_session.TF_SessionMakeCallable(\n\u001b[0;32m-> 1425\u001b[0;31m               session._session, options_ptr, status)\n\u001b[0m\u001b[1;32m   1426\u001b[0m       \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1427\u001b[0m         \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_DeleteBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptions_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "H-0C67n3Bsat",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "grid.best_params_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gRTPtDZ1W6xi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 6344
        },
        "outputId": "0c109ce7-952a-4b1c-b1ee-629d553496ef"
      },
      "cell_type": "code",
      "source": [
        "# Create outer cross-validation loop to assess average performance of hyperparameter model found by inner cross-validation loop\n",
        "outer_fold = KFold(n_splits=5, shuffle=True, random_state=rand_state)\n",
        "# Create array to track performance of models identified by inner loop\n",
        "outer_scores = []\n",
        "\n",
        "# The outer cross-validation loop\n",
        "for outfold, (outer_train_index, outer_test_index) in enumerate(outer_fold.split(train_dataframe), 1):\n",
        "  print(\"(Outer) Assessing performance on fold \" + str(outfold))\n",
        "  \n",
        "  outer_feature_train, outer_label_train = process_data(train_dataframe.iloc[outer_train_index].copy())\n",
        "  outer_feature_test, outer_label_test = process_data(train_dataframe.iloc[outer_test_index].copy())\n",
        "  \n",
        "  # Create inner cross-validation loop to optimize hyperparameters\n",
        "  inner_fold = KFold(n_splits=5, shuffle=True, random_state=rand_state)\n",
        "  # Create array to track performance of models with each hyperparameter combination\n",
        "  inner_mean_scores = []\n",
        "  \n",
        "  # Assorted hyperparameters to test and the dict compiling them\n",
        "  learn_rate = [0.001, 0.01]#, 0.1, 0.25, 0.5]\n",
        "  dropout_rate = [0.0, 0.5]#, 0.2, 0.4, 0.6, 0.8]\n",
        "  #dropout_rate_2 = dropout_rate_1.copy()\n",
        "  neurons = [16, 64]#[1, 4, 16, 64]\n",
        "  #neurons_2 = neurons_1.copy()\n",
        "  #epochs = [10, 50]#, 100, 1000]\n",
        "  parameters = dict(#learn_rate=learn_rate,\n",
        "                    #dropout_rate=dropout_rate,\n",
        "                    #dropout_rate_2=dropout_rate_2,\n",
        "                    neurons=neurons,\n",
        "                    #neurons_2=neurons_2,\n",
        "                    #epochs=epochs\n",
        "                   )\n",
        "  \n",
        "  # The inner cross-validation loop\n",
        "  for infold, (inner_train_index, inner_test_index) in enumerate(inner_fold.split(outer_feature_train), 1):\n",
        "    print(\"(Inner) Assessing hyperparameter performance on fold \" + str(infold))\n",
        "    \n",
        "    inner_feature_train, inner_feature_test = outer_feature_train.iloc[inner_train_index], outer_feature_train.iloc[inner_test_index]\n",
        "    inner_label_train, inner_label_test = outer_label_train.iloc[inner_train_index], outer_label_train.iloc[inner_test_index]\n",
        "    \n",
        "    inner_model = KerasRegressor(build_fn=build_model)\n",
        "    grid = GridSearchCV(estimator=inner_model, param_grid=parameters, scoring='neg_mean_squared_error', cv=3)\n",
        "    grid_result = grid.fit(inner_feature_train, inner_label_train)\n",
        "    # summarize results\n",
        "    print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "    means = grid_result.cv_results_['mean_test_score']\n",
        "    stds = grid_result.cv_results_['std_test_score']\n",
        "    params = grid_result.cv_results_['params']\n",
        "    for mean, stdev, param in zip(means, stds, params):\n",
        "      print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
        "  \n",
        "  \n",
        "  best_model = None\n",
        "  best_model = build_model()\n",
        "  outer_history = train_model(best_model, outer_feature_train, outer_label_train, outer_feature_test, outer_label_test, epochs=100)\n",
        "  outer_hist = pd.DataFrame(outer_history.history)\n",
        "  display.display(outer_hist.tail())"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(Outer) Assessing performance on fold 1\n",
            "(Inner) Assessing hyperparameter performance on fold 1\n",
            "168/168 [==============================] - 0s 3ms/sample - loss: 6.6862 - mean_absolute_error: 2.5431 - mean_squared_error: 6.6862\n",
            "168/168 [==============================] - 0s 3ms/sample - loss: 6.8431 - mean_absolute_error: 2.5644 - mean_squared_error: 6.8431\n",
            "168/168 [==============================] - 0s 3ms/sample - loss: 4.9501 - mean_absolute_error: 2.1733 - mean_squared_error: 4.9501\n",
            "168/168 [==============================] - 0s 3ms/sample - loss: 4.7114 - mean_absolute_error: 2.0999 - mean_squared_error: 4.7114\n",
            "168/168 [==============================] - 0s 3ms/sample - loss: 5.2524 - mean_absolute_error: 2.2251 - mean_squared_error: 5.2524\n",
            "168/168 [==============================] - 0s 3ms/sample - loss: 4.5440 - mean_absolute_error: 2.0535 - mean_squared_error: 4.5440\n",
            "252/252 [==============================] - 0s 2ms/sample - loss: 6.2779 - mean_absolute_error: 2.4336 - mean_squared_error: 6.2779\n",
            "Best: -3.067360 using {'neurons': 64}\n",
            "-4.994781 (0.760710) with: {'neurons': 16}\n",
            "-3.067360 (0.178459) with: {'neurons': 64}\n",
            "(Inner) Assessing hyperparameter performance on fold 2\n",
            "168/168 [==============================] - 0s 3ms/sample - loss: 5.4483 - mean_absolute_error: 2.2617 - mean_squared_error: 5.4483\n",
            "168/168 [==============================] - 1s 3ms/sample - loss: 5.0142 - mean_absolute_error: 2.1215 - mean_squared_error: 5.0142\n",
            "168/168 [==============================] - 1s 3ms/sample - loss: 6.7142 - mean_absolute_error: 2.5443 - mean_squared_error: 6.7142\n",
            "168/168 [==============================] - 1s 3ms/sample - loss: 5.7480 - mean_absolute_error: 2.3292 - mean_squared_error: 5.7480\n",
            "168/168 [==============================] - 1s 3ms/sample - loss: 4.9981 - mean_absolute_error: 2.1263 - mean_squared_error: 4.9981\n",
            "168/168 [==============================] - 1s 3ms/sample - loss: 4.2774 - mean_absolute_error: 2.0040 - mean_squared_error: 4.2774\n",
            "252/252 [==============================] - 1s 2ms/sample - loss: 3.5705 - mean_absolute_error: 1.7798 - mean_squared_error: 3.5705\n",
            "Best: -3.368969 using {'neurons': 64}\n",
            "-4.769016 (0.477469) with: {'neurons': 16}\n",
            "-3.368969 (0.834800) with: {'neurons': 64}\n",
            "(Inner) Assessing hyperparameter performance on fold 3\n",
            "168/168 [==============================] - 1s 3ms/sample - loss: 4.9347 - mean_absolute_error: 2.1177 - mean_squared_error: 4.9347\n",
            "168/168 [==============================] - 1s 3ms/sample - loss: 5.5582 - mean_absolute_error: 2.2686 - mean_squared_error: 5.5582\n",
            "168/168 [==============================] - 1s 4ms/sample - loss: 5.7730 - mean_absolute_error: 2.3594 - mean_squared_error: 5.7730\n",
            "168/168 [==============================] - 1s 4ms/sample - loss: 5.1811 - mean_absolute_error: 2.1958 - mean_squared_error: 5.1811\n",
            "168/168 [==============================] - 1s 4ms/sample - loss: 5.8257 - mean_absolute_error: 2.3444 - mean_squared_error: 5.8257\n",
            "168/168 [==============================] - 1s 4ms/sample - loss: 5.7744 - mean_absolute_error: 2.3449 - mean_squared_error: 5.7744\n",
            "252/252 [==============================] - 1s 3ms/sample - loss: 2.7066 - mean_absolute_error: 1.5173 - mean_squared_error: 2.7066\n",
            "Best: -3.568667 using {'neurons': 64}\n",
            "-4.260035 (0.297585) with: {'neurons': 16}\n",
            "-3.568667 (0.103905) with: {'neurons': 64}\n",
            "(Inner) Assessing hyperparameter performance on fold 4\n",
            "168/168 [==============================] - 1s 4ms/sample - loss: 2.9855 - mean_absolute_error: 1.5712 - mean_squared_error: 2.9855\n",
            "168/168 [==============================] - 1s 4ms/sample - loss: 5.1368 - mean_absolute_error: 2.2109 - mean_squared_error: 5.1368\n",
            "168/168 [==============================] - 1s 4ms/sample - loss: 6.7536 - mean_absolute_error: 2.5224 - mean_squared_error: 6.7536\n",
            "168/168 [==============================] - 1s 4ms/sample - loss: 3.3927 - mean_absolute_error: 1.6304 - mean_squared_error: 3.3927\n",
            "168/168 [==============================] - 1s 4ms/sample - loss: 4.3904 - mean_absolute_error: 2.0075 - mean_squared_error: 4.3904\n",
            "168/168 [==============================] - 1s 4ms/sample - loss: 3.3115 - mean_absolute_error: 1.7142 - mean_squared_error: 3.3115\n",
            "252/252 [==============================] - 1s 3ms/sample - loss: 4.9909 - mean_absolute_error: 2.1420 - mean_squared_error: 4.9909\n",
            "Best: -2.123536 using {'neurons': 64}\n",
            "-3.804452 (0.811591) with: {'neurons': 16}\n",
            "-2.123536 (0.432052) with: {'neurons': 64}\n",
            "(Inner) Assessing hyperparameter performance on fold 5\n",
            "168/168 [==============================] - 1s 4ms/sample - loss: 5.6051 - mean_absolute_error: 2.2996 - mean_squared_error: 5.6051\n",
            "168/168 [==============================] - 1s 4ms/sample - loss: 8.2478 - mean_absolute_error: 2.8081 - mean_squared_error: 8.2478\n",
            "168/168 [==============================] - 1s 4ms/sample - loss: 5.8133 - mean_absolute_error: 2.3406 - mean_squared_error: 5.8133\n",
            "168/168 [==============================] - 1s 4ms/sample - loss: 4.9467 - mean_absolute_error: 2.1082 - mean_squared_error: 4.9467\n",
            "168/168 [==============================] - 1s 4ms/sample - loss: 4.2790 - mean_absolute_error: 1.9377 - mean_squared_error: 4.2790\n",
            "168/168 [==============================] - 1s 5ms/sample - loss: 6.6532 - mean_absolute_error: 2.5300 - mean_squared_error: 6.6532\n",
            "252/252 [==============================] - 1s 3ms/sample - loss: 3.8551 - mean_absolute_error: 1.8454 - mean_squared_error: 3.8551\n",
            "Best: -3.293345 using {'neurons': 64}\n",
            "-5.108787 (0.929489) with: {'neurons': 16}\n",
            "-3.293345 (0.660154) with: {'neurons': 64}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>mean_absolute_error</th>\n",
              "      <th>mean_squared_error</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>val_mean_absolute_error</th>\n",
              "      <th>val_mean_squared_error</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>0.156</td>\n",
              "      <td>0.310</td>\n",
              "      <td>0.156</td>\n",
              "      <td>0.094</td>\n",
              "      <td>0.235</td>\n",
              "      <td>0.094</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>0.153</td>\n",
              "      <td>0.306</td>\n",
              "      <td>0.153</td>\n",
              "      <td>0.096</td>\n",
              "      <td>0.239</td>\n",
              "      <td>0.096</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>0.150</td>\n",
              "      <td>0.301</td>\n",
              "      <td>0.150</td>\n",
              "      <td>0.086</td>\n",
              "      <td>0.224</td>\n",
              "      <td>0.086</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>0.146</td>\n",
              "      <td>0.296</td>\n",
              "      <td>0.146</td>\n",
              "      <td>0.088</td>\n",
              "      <td>0.227</td>\n",
              "      <td>0.088</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>0.143</td>\n",
              "      <td>0.292</td>\n",
              "      <td>0.143</td>\n",
              "      <td>0.089</td>\n",
              "      <td>0.230</td>\n",
              "      <td>0.089</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    loss  mean_absolute_error  mean_squared_error  val_loss  \\\n",
              "95 0.156                0.310               0.156     0.094   \n",
              "96 0.153                0.306               0.153     0.096   \n",
              "97 0.150                0.301               0.150     0.086   \n",
              "98 0.146                0.296               0.146     0.088   \n",
              "99 0.143                0.292               0.143     0.089   \n",
              "\n",
              "    val_mean_absolute_error  val_mean_squared_error  \n",
              "95                    0.235                   0.094  \n",
              "96                    0.239                   0.096  \n",
              "97                    0.224                   0.086  \n",
              "98                    0.227                   0.088  \n",
              "99                    0.230                   0.089  "
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "(Outer) Assessing performance on fold 2\n",
            "(Inner) Assessing hyperparameter performance on fold 1\n",
            "170/170 [==============================] - 1s 5ms/sample - loss: 4.7639 - mean_absolute_error: 2.0796 - mean_squared_error: 4.7639\n",
            "171/171 [==============================] - 1s 5ms/sample - loss: 5.8843 - mean_absolute_error: 2.3493 - mean_squared_error: 5.8843\n",
            "171/171 [==============================] - 1s 5ms/sample - loss: 4.3809 - mean_absolute_error: 2.0214 - mean_squared_error: 4.3809\n",
            "170/170 [==============================] - 1s 5ms/sample - loss: 3.6048 - mean_absolute_error: 1.7823 - mean_squared_error: 3.6048\n",
            "171/171 [==============================] - 1s 5ms/sample - loss: 5.0818 - mean_absolute_error: 2.1465 - mean_squared_error: 5.0818\n",
            "171/171 [==============================] - 1s 5ms/sample - loss: 5.9260 - mean_absolute_error: 2.3694 - mean_squared_error: 5.9260\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "256/256 [==============================] - 1s 3ms/sample - loss: 3.5352 - mean_absolute_error: 1.7676 - mean_squared_error: 3.5352\n",
            "Best: -3.019333 using {'neurons': 64}\n",
            "-4.096120 (0.654263) with: {'neurons': 16}\n",
            "-3.019333 (0.551953) with: {'neurons': 64}\n",
            "(Inner) Assessing hyperparameter performance on fold 2\n",
            "171/171 [==============================] - 1s 5ms/sample - loss: 7.3174 - mean_absolute_error: 2.6519 - mean_squared_error: 7.3174\n",
            "171/171 [==============================] - 1s 5ms/sample - loss: 5.9167 - mean_absolute_error: 2.3188 - mean_squared_error: 5.9167\n",
            "172/172 [==============================] - 1s 5ms/sample - loss: 5.8310 - mean_absolute_error: 2.3573 - mean_squared_error: 5.8310\n",
            "171/171 [==============================] - 1s 5ms/sample - loss: 3.8471 - mean_absolute_error: 1.8461 - mean_squared_error: 3.8471\n",
            "171/171 [==============================] - 1s 5ms/sample - loss: 4.8456 - mean_absolute_error: 2.1033 - mean_squared_error: 4.8456\n",
            "172/172 [==============================] - 1s 5ms/sample - loss: 5.0245 - mean_absolute_error: 2.1510 - mean_squared_error: 5.0245\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "257/257 [==============================] - 1s 4ms/sample - loss: 3.4759 - mean_absolute_error: 1.7209 - mean_squared_error: 3.4759\n",
            "Best: -2.683231 using {'neurons': 64}\n",
            "-5.159980 (0.940233) with: {'neurons': 16}\n",
            "-2.683231 (0.174536) with: {'neurons': 64}\n",
            "(Inner) Assessing hyperparameter performance on fold 3\n",
            "171/171 [==============================] - 1s 6ms/sample - loss: 6.9773 - mean_absolute_error: 2.5831 - mean_squared_error: 6.9773\n",
            "171/171 [==============================] - 1s 5ms/sample - loss: 8.2665 - mean_absolute_error: 2.8310 - mean_squared_error: 8.2665\n",
            "172/172 [==============================] - 1s 5ms/sample - loss: 3.8174 - mean_absolute_error: 1.8812 - mean_squared_error: 3.8174\n",
            "171/171 [==============================] - 1s 6ms/sample - loss: 4.0749 - mean_absolute_error: 1.9266 - mean_squared_error: 4.0749\n",
            "171/171 [==============================] - 1s 6ms/sample - loss: 4.4599 - mean_absolute_error: 2.0123 - mean_squared_error: 4.4599\n",
            "172/172 [==============================] - 1s 6ms/sample - loss: 3.8695 - mean_absolute_error: 1.8583 - mean_squared_error: 3.8695\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "257/257 [==============================] - 1s 4ms/sample - loss: 3.8179 - mean_absolute_error: 1.8492 - mean_squared_error: 3.8179\n",
            "Best: -2.286386 using {'neurons': 64}\n",
            "-5.126822 (1.717334) with: {'neurons': 16}\n",
            "-2.286386 (0.217856) with: {'neurons': 64}\n",
            "(Inner) Assessing hyperparameter performance on fold 4\n",
            "171/171 [==============================] - 1s 6ms/sample - loss: 6.4908 - mean_absolute_error: 2.4866 - mean_squared_error: 6.4908\n",
            "171/171 [==============================] - 1s 6ms/sample - loss: 2.9939 - mean_absolute_error: 1.5729 - mean_squared_error: 2.9939\n",
            "172/172 [==============================] - 1s 6ms/sample - loss: 5.9099 - mean_absolute_error: 2.3690 - mean_squared_error: 5.9099\n",
            "171/171 [==============================] - 1s 6ms/sample - loss: 5.8896 - mean_absolute_error: 2.3562 - mean_squared_error: 5.8896\n",
            "171/171 [==============================] - 1s 6ms/sample - loss: 4.4177 - mean_absolute_error: 2.0224 - mean_squared_error: 4.4177\n",
            "172/172 [==============================] - 1s 6ms/sample - loss: 5.2126 - mean_absolute_error: 2.2050 - mean_squared_error: 5.2126\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "257/257 [==============================] - 1s 4ms/sample - loss: 4.4057 - mean_absolute_error: 1.9848 - mean_squared_error: 4.4057\n",
            "Best: -3.339873 using {'neurons': 64}\n",
            "-4.195506 (1.753846) with: {'neurons': 16}\n",
            "-3.339873 (1.088709) with: {'neurons': 64}\n",
            "(Inner) Assessing hyperparameter performance on fold 5\n",
            "171/171 [==============================] - 1s 6ms/sample - loss: 7.8133 - mean_absolute_error: 2.7445 - mean_squared_error: 7.8133\n",
            "171/171 [==============================] - 1s 6ms/sample - loss: 4.8070 - mean_absolute_error: 2.0614 - mean_squared_error: 4.8070\n",
            "172/172 [==============================] - 1s 6ms/sample - loss: 4.9871 - mean_absolute_error: 2.1595 - mean_squared_error: 4.9871\n",
            "171/171 [==============================] - 1s 6ms/sample - loss: 4.7131 - mean_absolute_error: 2.0887 - mean_squared_error: 4.7131\n",
            "171/171 [==============================] - 1s 6ms/sample - loss: 4.9024 - mean_absolute_error: 2.1262 - mean_squared_error: 4.9024\n",
            "172/172 [==============================] - 1s 6ms/sample - loss: 6.4445 - mean_absolute_error: 2.4811 - mean_squared_error: 6.4445\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "257/257 [==============================] - 1s 4ms/sample - loss: 3.8758 - mean_absolute_error: 1.8425 - mean_squared_error: 3.8758\n",
            "Best: -3.403662 using {'neurons': 64}\n",
            "-4.818394 (1.562586) with: {'neurons': 16}\n",
            "-3.403662 (0.606078) with: {'neurons': 64}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>mean_absolute_error</th>\n",
              "      <th>mean_squared_error</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>val_mean_absolute_error</th>\n",
              "      <th>val_mean_squared_error</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>91</th>\n",
              "      <td>0.087</td>\n",
              "      <td>0.197</td>\n",
              "      <td>0.087</td>\n",
              "      <td>0.086</td>\n",
              "      <td>0.206</td>\n",
              "      <td>0.086</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>92</th>\n",
              "      <td>0.088</td>\n",
              "      <td>0.197</td>\n",
              "      <td>0.088</td>\n",
              "      <td>0.095</td>\n",
              "      <td>0.227</td>\n",
              "      <td>0.095</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93</th>\n",
              "      <td>0.088</td>\n",
              "      <td>0.199</td>\n",
              "      <td>0.088</td>\n",
              "      <td>0.080</td>\n",
              "      <td>0.193</td>\n",
              "      <td>0.080</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94</th>\n",
              "      <td>0.087</td>\n",
              "      <td>0.196</td>\n",
              "      <td>0.087</td>\n",
              "      <td>0.084</td>\n",
              "      <td>0.202</td>\n",
              "      <td>0.084</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>0.087</td>\n",
              "      <td>0.196</td>\n",
              "      <td>0.087</td>\n",
              "      <td>0.080</td>\n",
              "      <td>0.191</td>\n",
              "      <td>0.080</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    loss  mean_absolute_error  mean_squared_error  val_loss  \\\n",
              "91 0.087                0.197               0.087     0.086   \n",
              "92 0.088                0.197               0.088     0.095   \n",
              "93 0.088                0.199               0.088     0.080   \n",
              "94 0.087                0.196               0.087     0.084   \n",
              "95 0.087                0.196               0.087     0.080   \n",
              "\n",
              "    val_mean_absolute_error  val_mean_squared_error  \n",
              "91                    0.206                   0.086  \n",
              "92                    0.227                   0.095  \n",
              "93                    0.193                   0.080  \n",
              "94                    0.202                   0.084  \n",
              "95                    0.191                   0.080  "
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "(Outer) Assessing performance on fold 3\n",
            "(Inner) Assessing hyperparameter performance on fold 1\n",
            "166/166 [==============================] - 1s 7ms/sample - loss: 5.8008 - mean_absolute_error: 2.3557 - mean_squared_error: 5.8008\n",
            "167/167 [==============================] - 1s 7ms/sample - loss: 8.2327 - mean_absolute_error: 2.8180 - mean_squared_error: 8.2327\n",
            "167/167 [==============================] - 1s 7ms/sample - loss: 6.1591 - mean_absolute_error: 2.4106 - mean_squared_error: 6.1591\n",
            "166/166 [==============================] - 1s 7ms/sample - loss: 3.8141 - mean_absolute_error: 1.8574 - mean_squared_error: 3.8141\n",
            "167/167 [==============================] - 1s 7ms/sample - loss: 4.4160 - mean_absolute_error: 2.0289 - mean_squared_error: 4.4160\n",
            "167/167 [==============================] - 1s 7ms/sample - loss: 4.5853 - mean_absolute_error: 2.0704 - mean_squared_error: 4.5853\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "250/250 [==============================] - 1s 5ms/sample - loss: 6.5557 - mean_absolute_error: 2.5119 - mean_squared_error: 6.5557\n",
            "Best: -2.459351 using {'neurons': 64}\n",
            "-5.421214 (0.844713) with: {'neurons': 16}\n",
            "-2.459351 (0.142295) with: {'neurons': 64}\n",
            "(Inner) Assessing hyperparameter performance on fold 2\n",
            "166/166 [==============================] - 1s 7ms/sample - loss: 5.6354 - mean_absolute_error: 2.2932 - mean_squared_error: 5.6354\n",
            "167/167 [==============================] - 1s 7ms/sample - loss: 7.3705 - mean_absolute_error: 2.6464 - mean_squared_error: 7.3705\n",
            "167/167 [==============================] - 1s 7ms/sample - loss: 6.0690 - mean_absolute_error: 2.4064 - mean_squared_error: 6.0690\n",
            "166/166 [==============================] - 1s 7ms/sample - loss: 5.4097 - mean_absolute_error: 2.2297 - mean_squared_error: 5.4097\n",
            "167/167 [==============================] - 1s 7ms/sample - loss: 5.7092 - mean_absolute_error: 2.3203 - mean_squared_error: 5.7092\n",
            "167/167 [==============================] - 1s 8ms/sample - loss: 3.9390 - mean_absolute_error: 1.8727 - mean_squared_error: 3.9390\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "250/250 [==============================] - 2s 7ms/sample - loss: 3.5277 - mean_absolute_error: 1.7606 - mean_squared_error: 3.5277\n",
            "Best: -2.970616 using {'neurons': 64}\n",
            "-5.121244 (0.753339) with: {'neurons': 16}\n",
            "-2.970616 (0.866074) with: {'neurons': 64}\n",
            "(Inner) Assessing hyperparameter performance on fold 3\n",
            "166/166 [==============================] - 1s 8ms/sample - loss: 5.6310 - mean_absolute_error: 2.3100 - mean_squared_error: 5.6310\n",
            "167/167 [==============================] - 1s 8ms/sample - loss: 5.2854 - mean_absolute_error: 2.2481 - mean_squared_error: 5.2854\n",
            "167/167 [==============================] - 1s 8ms/sample - loss: 5.2847 - mean_absolute_error: 2.2181 - mean_squared_error: 5.2847\n",
            "166/166 [==============================] - 1s 8ms/sample - loss: 4.7860 - mean_absolute_error: 2.0557 - mean_squared_error: 4.7860\n",
            "167/167 [==============================] - 1s 8ms/sample - loss: 5.2558 - mean_absolute_error: 2.2225 - mean_squared_error: 5.2558\n",
            "167/167 [==============================] - 1s 8ms/sample - loss: 5.4426 - mean_absolute_error: 2.2507 - mean_squared_error: 5.4426\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "250/250 [==============================] - 1s 5ms/sample - loss: 5.8741 - mean_absolute_error: 2.3397 - mean_squared_error: 5.8741\n",
            "Best: -3.338089 using {'neurons': 64}\n",
            "-4.314854 (0.420677) with: {'neurons': 16}\n",
            "-3.338089 (0.022669) with: {'neurons': 64}\n",
            "(Inner) Assessing hyperparameter performance on fold 4\n",
            "167/167 [==============================] - 1s 8ms/sample - loss: 7.0874 - mean_absolute_error: 2.6231 - mean_squared_error: 7.0874\n",
            "167/167 [==============================] - 1s 8ms/sample - loss: 8.0955 - mean_absolute_error: 2.7951 - mean_squared_error: 8.0955\n",
            "168/168 [==============================] - 1s 8ms/sample - loss: 7.0952 - mean_absolute_error: 2.6142 - mean_squared_error: 7.0952\n",
            "167/167 [==============================] - 1s 8ms/sample - loss: 5.6288 - mean_absolute_error: 2.3145 - mean_squared_error: 5.6288\n",
            "167/167 [==============================] - 1s 8ms/sample - loss: 5.3575 - mean_absolute_error: 2.2242 - mean_squared_error: 5.3575\n",
            "168/168 [==============================] - 1s 8ms/sample - loss: 6.8520 - mean_absolute_error: 2.5609 - mean_squared_error: 6.8520\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "251/251 [==============================] - 1s 6ms/sample - loss: 5.2802 - mean_absolute_error: 2.2041 - mean_squared_error: 5.2802\n",
            "Best: -3.807395 using {'neurons': 64}\n",
            "-6.341001 (0.660318) with: {'neurons': 16}\n",
            "-3.807395 (0.306264) with: {'neurons': 64}\n",
            "(Inner) Assessing hyperparameter performance on fold 5\n",
            "167/167 [==============================] - 1s 8ms/sample - loss: 5.6773 - mean_absolute_error: 2.3274 - mean_squared_error: 5.6773\n",
            "167/167 [==============================] - 1s 9ms/sample - loss: 6.6595 - mean_absolute_error: 2.5328 - mean_squared_error: 6.6595\n",
            "168/168 [==============================] - 1s 8ms/sample - loss: 6.8722 - mean_absolute_error: 2.5654 - mean_squared_error: 6.8722\n",
            "167/167 [==============================] - 1s 9ms/sample - loss: 6.7461 - mean_absolute_error: 2.5397 - mean_squared_error: 6.7461\n",
            "167/167 [==============================] - 1s 9ms/sample - loss: 5.3725 - mean_absolute_error: 2.2243 - mean_squared_error: 5.3725\n",
            "168/168 [==============================] - 1s 9ms/sample - loss: 6.5373 - mean_absolute_error: 2.4976 - mean_squared_error: 6.5373\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "251/251 [==============================] - 2s 6ms/sample - loss: 3.5851 - mean_absolute_error: 1.7714 - mean_squared_error: 3.5851\n",
            "Best: -4.121561 using {'neurons': 64}\n",
            "-5.328840 (0.101047) with: {'neurons': 16}\n",
            "-4.121561 (0.839249) with: {'neurons': 64}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>mean_absolute_error</th>\n",
              "      <th>mean_squared_error</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>val_mean_absolute_error</th>\n",
              "      <th>val_mean_squared_error</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>0.079</td>\n",
              "      <td>0.188</td>\n",
              "      <td>0.079</td>\n",
              "      <td>0.119</td>\n",
              "      <td>0.234</td>\n",
              "      <td>0.119</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>0.079</td>\n",
              "      <td>0.186</td>\n",
              "      <td>0.079</td>\n",
              "      <td>0.125</td>\n",
              "      <td>0.246</td>\n",
              "      <td>0.125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>0.078</td>\n",
              "      <td>0.182</td>\n",
              "      <td>0.078</td>\n",
              "      <td>0.120</td>\n",
              "      <td>0.235</td>\n",
              "      <td>0.120</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>0.079</td>\n",
              "      <td>0.189</td>\n",
              "      <td>0.079</td>\n",
              "      <td>0.116</td>\n",
              "      <td>0.227</td>\n",
              "      <td>0.116</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>0.078</td>\n",
              "      <td>0.185</td>\n",
              "      <td>0.078</td>\n",
              "      <td>0.116</td>\n",
              "      <td>0.227</td>\n",
              "      <td>0.116</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    loss  mean_absolute_error  mean_squared_error  val_loss  \\\n",
              "95 0.079                0.188               0.079     0.119   \n",
              "96 0.079                0.186               0.079     0.125   \n",
              "97 0.078                0.182               0.078     0.120   \n",
              "98 0.079                0.189               0.079     0.116   \n",
              "99 0.078                0.185               0.078     0.116   \n",
              "\n",
              "    val_mean_absolute_error  val_mean_squared_error  \n",
              "95                    0.234                   0.119  \n",
              "96                    0.246                   0.125  \n",
              "97                    0.235                   0.120  \n",
              "98                    0.227                   0.116  \n",
              "99                    0.227                   0.116  "
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "(Outer) Assessing performance on fold 4\n",
            "(Inner) Assessing hyperparameter performance on fold 1\n",
            "166/166 [==============================] - 1s 9ms/sample - loss: 4.8738 - mean_absolute_error: 2.1079 - mean_squared_error: 4.8738\n",
            "167/167 [==============================] - 1s 9ms/sample - loss: 7.8210 - mean_absolute_error: 2.7214 - mean_squared_error: 7.8210\n",
            "167/167 [==============================] - 1s 9ms/sample - loss: 5.5347 - mean_absolute_error: 2.2917 - mean_squared_error: 5.5347\n",
            "166/166 [==============================] - 2s 9ms/sample - loss: 5.3874 - mean_absolute_error: 2.2519 - mean_squared_error: 5.3874\n",
            "167/167 [==============================] - 2s 9ms/sample - loss: 5.1498 - mean_absolute_error: 2.1812 - mean_squared_error: 5.1498\n",
            "167/167 [==============================] - 2s 9ms/sample - loss: 4.0706 - mean_absolute_error: 1.9400 - mean_squared_error: 4.0706\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "250/250 [==============================] - 2s 6ms/sample - loss: 4.5761 - mean_absolute_error: 2.0500 - mean_squared_error: 4.5761\n",
            "Best: -3.130206 using {'neurons': 64}\n",
            "-4.626580 (0.588257) with: {'neurons': 16}\n",
            "-3.130206 (0.643066) with: {'neurons': 64}\n",
            "(Inner) Assessing hyperparameter performance on fold 2\n",
            "166/166 [==============================] - 2s 9ms/sample - loss: 7.0059 - mean_absolute_error: 2.6004 - mean_squared_error: 7.0059\n",
            "167/167 [==============================] - 2s 9ms/sample - loss: 6.4022 - mean_absolute_error: 2.4437 - mean_squared_error: 6.4022\n",
            "167/167 [==============================] - 2s 9ms/sample - loss: 4.6992 - mean_absolute_error: 2.1030 - mean_squared_error: 4.6992\n",
            "166/166 [==============================] - 2s 9ms/sample - loss: 4.4877 - mean_absolute_error: 2.0527 - mean_squared_error: 4.4877\n",
            "167/167 [==============================] - 2s 9ms/sample - loss: 5.1579 - mean_absolute_error: 2.1786 - mean_squared_error: 5.1579\n",
            "167/167 [==============================] - 2s 9ms/sample - loss: 5.2497 - mean_absolute_error: 2.2486 - mean_squared_error: 5.2497\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "250/250 [==============================] - 2s 6ms/sample - loss: 3.8564 - mean_absolute_error: 1.8556 - mean_squared_error: 3.8564\n",
            "Best: -3.061955 using {'neurons': 64}\n",
            "-4.804808 (1.280577) with: {'neurons': 16}\n",
            "-3.061955 (0.267611) with: {'neurons': 64}\n",
            "(Inner) Assessing hyperparameter performance on fold 3\n",
            "166/166 [==============================] - 2s 10ms/sample - loss: 7.0409 - mean_absolute_error: 2.6004 - mean_squared_error: 7.0409\n",
            "167/167 [==============================] - 2s 10ms/sample - loss: 6.3217 - mean_absolute_error: 2.4426 - mean_squared_error: 6.3217\n",
            "167/167 [==============================] - 2s 10ms/sample - loss: 5.3817 - mean_absolute_error: 2.2346 - mean_squared_error: 5.3817\n",
            "166/166 [==============================] - 2s 10ms/sample - loss: 3.9192 - mean_absolute_error: 1.8518 - mean_squared_error: 3.9192\n",
            "167/167 [==============================] - 2s 10ms/sample - loss: 4.0371 - mean_absolute_error: 1.8992 - mean_squared_error: 4.0371\n",
            "167/167 [==============================] - 2s 10ms/sample - loss: 3.4544 - mean_absolute_error: 1.7692 - mean_squared_error: 3.4544\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "250/250 [==============================] - 2s 7ms/sample - loss: 3.9474 - mean_absolute_error: 1.8657 - mean_squared_error: 3.9474\n",
            "Best: -2.133408 using {'neurons': 64}\n",
            "-5.112575 (0.936510) with: {'neurons': 16}\n",
            "-2.133408 (0.481917) with: {'neurons': 64}\n",
            "(Inner) Assessing hyperparameter performance on fold 4\n",
            "167/167 [==============================] - 2s 11ms/sample - loss: 6.0170 - mean_absolute_error: 2.4014 - mean_squared_error: 6.0170\n",
            "167/167 [==============================] - 2s 10ms/sample - loss: 4.0903 - mean_absolute_error: 1.9058 - mean_squared_error: 4.0903\n",
            "168/168 [==============================] - 2s 10ms/sample - loss: 6.3595 - mean_absolute_error: 2.4718 - mean_squared_error: 6.3595\n",
            "167/167 [==============================] - 2s 10ms/sample - loss: 5.9433 - mean_absolute_error: 2.3656 - mean_squared_error: 5.9433\n",
            "167/167 [==============================] - 2s 10ms/sample - loss: 4.1372 - mean_absolute_error: 1.9296 - mean_squared_error: 4.1372\n",
            "168/168 [==============================] - 2s 11ms/sample - loss: 5.0027 - mean_absolute_error: 2.1881 - mean_squared_error: 5.0027\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "251/251 [==============================] - 2s 7ms/sample - loss: 5.7565 - mean_absolute_error: 2.2917 - mean_squared_error: 5.7565\n",
            "Best: -3.364693 using {'neurons': 64}\n",
            "-4.640500 (0.854941) with: {'neurons': 16}\n",
            "-3.364693 (0.816609) with: {'neurons': 64}\n",
            "(Inner) Assessing hyperparameter performance on fold 5\n",
            "167/167 [==============================] - 2s 10ms/sample - loss: 6.0498 - mean_absolute_error: 2.3982 - mean_squared_error: 6.0498\n",
            "167/167 [==============================] - 2s 11ms/sample - loss: 7.4394 - mean_absolute_error: 2.6828 - mean_squared_error: 7.4394\n",
            "168/168 [==============================] - 2s 10ms/sample - loss: 5.5065 - mean_absolute_error: 2.2989 - mean_squared_error: 5.5065\n",
            "167/167 [==============================] - 2s 11ms/sample - loss: 4.0079 - mean_absolute_error: 1.8976 - mean_squared_error: 4.0079\n",
            "167/167 [==============================] - 2s 11ms/sample - loss: 4.4463 - mean_absolute_error: 2.0077 - mean_squared_error: 4.4463\n",
            "168/168 [==============================] - 2s 10ms/sample - loss: 5.9798 - mean_absolute_error: 2.3963 - mean_squared_error: 5.9798\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "251/251 [==============================] - 2s 7ms/sample - loss: 4.4226 - mean_absolute_error: 1.9888 - mean_squared_error: 4.4226\n",
            "Best: -2.824739 using {'neurons': 64}\n",
            "-5.208573 (0.731259) with: {'neurons': 16}\n",
            "-2.824739 (0.188834) with: {'neurons': 64}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>mean_absolute_error</th>\n",
              "      <th>mean_squared_error</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>val_mean_absolute_error</th>\n",
              "      <th>val_mean_squared_error</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>0.081</td>\n",
              "      <td>0.194</td>\n",
              "      <td>0.081</td>\n",
              "      <td>0.101</td>\n",
              "      <td>0.211</td>\n",
              "      <td>0.101</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>0.080</td>\n",
              "      <td>0.194</td>\n",
              "      <td>0.080</td>\n",
              "      <td>0.101</td>\n",
              "      <td>0.217</td>\n",
              "      <td>0.101</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>0.080</td>\n",
              "      <td>0.194</td>\n",
              "      <td>0.080</td>\n",
              "      <td>0.101</td>\n",
              "      <td>0.210</td>\n",
              "      <td>0.101</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>0.080</td>\n",
              "      <td>0.194</td>\n",
              "      <td>0.080</td>\n",
              "      <td>0.100</td>\n",
              "      <td>0.211</td>\n",
              "      <td>0.100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>0.080</td>\n",
              "      <td>0.194</td>\n",
              "      <td>0.080</td>\n",
              "      <td>0.100</td>\n",
              "      <td>0.210</td>\n",
              "      <td>0.100</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    loss  mean_absolute_error  mean_squared_error  val_loss  \\\n",
              "95 0.081                0.194               0.081     0.101   \n",
              "96 0.080                0.194               0.080     0.101   \n",
              "97 0.080                0.194               0.080     0.101   \n",
              "98 0.080                0.194               0.080     0.100   \n",
              "99 0.080                0.194               0.080     0.100   \n",
              "\n",
              "    val_mean_absolute_error  val_mean_squared_error  \n",
              "95                    0.211                   0.101  \n",
              "96                    0.217                   0.101  \n",
              "97                    0.210                   0.101  \n",
              "98                    0.211                   0.100  \n",
              "99                    0.210                   0.100  "
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "(Outer) Assessing performance on fold 5\n",
            "(Inner) Assessing hyperparameter performance on fold 1\n",
            "169/169 [==============================] - 2s 11ms/sample - loss: 5.4623 - mean_absolute_error: 2.2594 - mean_squared_error: 5.4623\n",
            "169/169 [==============================] - 2s 11ms/sample - loss: 7.8487 - mean_absolute_error: 2.7623 - mean_squared_error: 7.8487\n",
            "170/170 [==============================] - 2s 11ms/sample - loss: 7.1734 - mean_absolute_error: 2.6397 - mean_squared_error: 7.1734\n",
            "169/169 [==============================] - 2s 11ms/sample - loss: 4.4545 - mean_absolute_error: 2.0259 - mean_squared_error: 4.4545\n",
            "169/169 [==============================] - 2s 12ms/sample - loss: 5.4457 - mean_absolute_error: 2.2798 - mean_squared_error: 5.4457\n",
            "170/170 [==============================] - 2s 11ms/sample - loss: 3.5319 - mean_absolute_error: 1.7668 - mean_squared_error: 3.5319\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "254/254 [==============================] - 2s 7ms/sample - loss: 3.4842 - mean_absolute_error: 1.7345 - mean_squared_error: 3.4842\n",
            "Best: -2.716081 using {'neurons': 64}\n",
            "-5.505947 (1.008215) with: {'neurons': 16}\n",
            "-2.716081 (0.706466) with: {'neurons': 64}\n",
            "(Inner) Assessing hyperparameter performance on fold 2\n",
            "169/169 [==============================] - 2s 11ms/sample - loss: 4.9381 - mean_absolute_error: 2.1799 - mean_squared_error: 4.9381\n",
            "169/169 [==============================] - 2s 11ms/sample - loss: 5.7681 - mean_absolute_error: 2.3194 - mean_squared_error: 5.7681\n",
            "170/170 [==============================] - 2s 11ms/sample - loss: 5.4584 - mean_absolute_error: 2.2788 - mean_squared_error: 5.4584\n",
            "169/169 [==============================] - 2s 11ms/sample - loss: 4.5622 - mean_absolute_error: 2.0289 - mean_squared_error: 4.5622\n",
            "169/169 [==============================] - 2s 11ms/sample - loss: 5.2044 - mean_absolute_error: 2.1986 - mean_squared_error: 5.2044\n",
            "170/170 [==============================] - 2s 11ms/sample - loss: 5.0593 - mean_absolute_error: 2.1738 - mean_squared_error: 5.0593\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "254/254 [==============================] - 2s 8ms/sample - loss: 5.6618 - mean_absolute_error: 2.2760 - mean_squared_error: 5.6618\n",
            "Best: -3.026513 using {'neurons': 64}\n",
            "-4.014593 (0.340677) with: {'neurons': 16}\n",
            "-3.026513 (0.280960) with: {'neurons': 64}\n",
            "(Inner) Assessing hyperparameter performance on fold 3\n",
            "169/169 [==============================] - 2s 12ms/sample - loss: 6.3033 - mean_absolute_error: 2.4597 - mean_squared_error: 6.3033\n",
            "169/169 [==============================] - 2s 12ms/sample - loss: 7.5309 - mean_absolute_error: 2.6928 - mean_squared_error: 7.5309\n",
            "170/170 [==============================] - 2s 11ms/sample - loss: 5.4915 - mean_absolute_error: 2.2819 - mean_squared_error: 5.4915\n",
            "169/169 [==============================] - 2s 12ms/sample - loss: 3.9211 - mean_absolute_error: 1.8791 - mean_squared_error: 3.9211\n",
            "169/169 [==============================] - 2s 11ms/sample - loss: 3.6443 - mean_absolute_error: 1.7937 - mean_squared_error: 3.6443\n",
            "170/170 [==============================] - 2s 12ms/sample - loss: 4.2406 - mean_absolute_error: 1.9906 - mean_squared_error: 4.2406\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "254/254 [==============================] - 2s 8ms/sample - loss: 5.7678 - mean_absolute_error: 2.2615 - mean_squared_error: 5.7678\n",
            "Best: -2.017688 using {'neurons': 64}\n",
            "-5.377189 (0.849823) with: {'neurons': 16}\n",
            "-2.017688 (0.216518) with: {'neurons': 64}\n",
            "(Inner) Assessing hyperparameter performance on fold 4\n",
            "170/170 [==============================] - 2s 12ms/sample - loss: 4.5478 - mean_absolute_error: 2.0624 - mean_squared_error: 4.5478\n",
            "170/170 [==============================] - 2s 12ms/sample - loss: 4.1739 - mean_absolute_error: 1.9780 - mean_squared_error: 4.1739\n",
            "170/170 [==============================] - 2s 12ms/sample - loss: 7.5139 - mean_absolute_error: 2.7040 - mean_squared_error: 7.5139\n",
            "170/170 [==============================] - 2s 12ms/sample - loss: 4.7394 - mean_absolute_error: 2.0833 - mean_squared_error: 4.7394\n",
            "170/170 [==============================] - 2s 12ms/sample - loss: 5.0774 - mean_absolute_error: 2.1743 - mean_squared_error: 5.0774\n",
            "170/170 [==============================] - 2s 12ms/sample - loss: 6.4697 - mean_absolute_error: 2.5000 - mean_squared_error: 6.4697\n",
            "255/255 [==============================] - 2s 8ms/sample - loss: 3.7050 - mean_absolute_error: 1.8376 - mean_squared_error: 3.7050\n",
            "Best: -3.431604 using {'neurons': 64}\n",
            "-4.368450 (1.136877) with: {'neurons': 16}\n",
            "-3.431604 (0.376224) with: {'neurons': 64}\n",
            "(Inner) Assessing hyperparameter performance on fold 5\n",
            "170/170 [==============================] - 2s 12ms/sample - loss: 7.1424 - mean_absolute_error: 2.6206 - mean_squared_error: 7.1424\n",
            "170/170 [==============================] - 2s 12ms/sample - loss: 5.9159 - mean_absolute_error: 2.3706 - mean_squared_error: 5.9159\n",
            "170/170 [==============================] - 2s 12ms/sample - loss: 6.3122 - mean_absolute_error: 2.4663 - mean_squared_error: 6.3122\n",
            "170/170 [==============================] - 2s 12ms/sample - loss: 7.8884 - mean_absolute_error: 2.7506 - mean_squared_error: 7.8884\n",
            "170/170 [==============================] - 2s 12ms/sample - loss: 4.3033 - mean_absolute_error: 1.9669 - mean_squared_error: 4.3033\n",
            "170/170 [==============================] - 2s 12ms/sample - loss: 5.0266 - mean_absolute_error: 2.1587 - mean_squared_error: 5.0266\n",
            "255/255 [==============================] - 2s 8ms/sample - loss: 5.5753 - mean_absolute_error: 2.2654 - mean_squared_error: 5.5753\n",
            "Best: -3.769269 using {'neurons': 64}\n",
            "-5.231784 (0.657668) with: {'neurons': 16}\n",
            "-3.769269 (1.585014) with: {'neurons': 64}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>mean_absolute_error</th>\n",
              "      <th>mean_squared_error</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>val_mean_absolute_error</th>\n",
              "      <th>val_mean_squared_error</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>0.105</td>\n",
              "      <td>0.222</td>\n",
              "      <td>0.105</td>\n",
              "      <td>0.087</td>\n",
              "      <td>0.218</td>\n",
              "      <td>0.087</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>0.104</td>\n",
              "      <td>0.222</td>\n",
              "      <td>0.104</td>\n",
              "      <td>0.087</td>\n",
              "      <td>0.219</td>\n",
              "      <td>0.087</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>0.103</td>\n",
              "      <td>0.218</td>\n",
              "      <td>0.103</td>\n",
              "      <td>0.086</td>\n",
              "      <td>0.217</td>\n",
              "      <td>0.086</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>0.102</td>\n",
              "      <td>0.216</td>\n",
              "      <td>0.102</td>\n",
              "      <td>0.087</td>\n",
              "      <td>0.219</td>\n",
              "      <td>0.087</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>0.102</td>\n",
              "      <td>0.218</td>\n",
              "      <td>0.102</td>\n",
              "      <td>0.086</td>\n",
              "      <td>0.217</td>\n",
              "      <td>0.086</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    loss  mean_absolute_error  mean_squared_error  val_loss  \\\n",
              "95 0.105                0.222               0.105     0.087   \n",
              "96 0.104                0.222               0.104     0.087   \n",
              "97 0.103                0.218               0.103     0.086   \n",
              "98 0.102                0.216               0.102     0.087   \n",
              "99 0.102                0.218               0.102     0.086   \n",
              "\n",
              "    val_mean_absolute_error  val_mean_squared_error  \n",
              "95                    0.218                   0.087  \n",
              "96                    0.219                   0.087  \n",
              "97                    0.217                   0.086  \n",
              "98                    0.219                   0.087  \n",
              "99                    0.217                   0.086  "
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "ccPjg5Hvxh08",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "end_fold_error = pd.DataFrame()\n",
        "\n",
        "# Loop through the k folds for cross validation\n",
        "for i, (train_index, test_index) in enumerate(kf.split(train_dataframe), 1):\n",
        "  print(\"Training on fold \" + str(i))\n",
        "  \n",
        "  feature_train, label_train = process_data(train_dataframe.iloc[train_index].copy())\n",
        "  feature_test, label_test = process_data(train_dataframe.iloc[test_index].copy())\n",
        "  \n",
        "  model = None\n",
        "  model = build_model()\n",
        "  \n",
        "  history = train_model(model, feature_train, label_train, feature_test, label_test)\n",
        "  mse_history = history.history['mean_squared_error']\n",
        "  val_mse_history = history.history['val_mean_squared_error']\n",
        "  end_fold_error = end_fold_error.append(\n",
        "      pd.Series([history.history['loss'][-1],\n",
        "                 history.history['mean_absolute_error'][-1],\n",
        "                 mse_history[-1], \n",
        "                 history.history['val_loss'][-1],\n",
        "                 history.history['val_mean_absolute_error'][-1],\n",
        "                 val_mse_history[-1]]\n",
        "                ), ignore_index=True)\n",
        "  print(\"Last training error: \" + str(mse_history[-1]))\n",
        "  print(\"Last validation error: \" + str(val_mse_history[-1]))\n",
        "\n",
        "#hist = pd.DataFrame(history.history)\n",
        "#hist['epoch'] = history.epoch\n",
        "#hist.tail()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Qdhb56jAL1MA",
        "colab_type": "code",
        "outputId": "1ff4708e-8d90-4158-a1c3-3d17a55db549",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        }
      },
      "cell_type": "code",
      "source": [
        "end_fold_error"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2.034</td>\n",
              "      <td>1.343</td>\n",
              "      <td>2.034</td>\n",
              "      <td>2.233</td>\n",
              "      <td>1.431</td>\n",
              "      <td>2.233</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.205</td>\n",
              "      <td>0.358</td>\n",
              "      <td>0.205</td>\n",
              "      <td>0.150</td>\n",
              "      <td>0.315</td>\n",
              "      <td>0.150</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2.044</td>\n",
              "      <td>1.350</td>\n",
              "      <td>2.044</td>\n",
              "      <td>2.082</td>\n",
              "      <td>1.352</td>\n",
              "      <td>2.082</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.240</td>\n",
              "      <td>0.358</td>\n",
              "      <td>0.240</td>\n",
              "      <td>0.207</td>\n",
              "      <td>0.345</td>\n",
              "      <td>0.207</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.069</td>\n",
              "      <td>1.360</td>\n",
              "      <td>2.069</td>\n",
              "      <td>1.850</td>\n",
              "      <td>1.257</td>\n",
              "      <td>1.850</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.158</td>\n",
              "      <td>0.293</td>\n",
              "      <td>0.158</td>\n",
              "      <td>0.121</td>\n",
              "      <td>0.280</td>\n",
              "      <td>0.121</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2.008</td>\n",
              "      <td>1.337</td>\n",
              "      <td>2.008</td>\n",
              "      <td>2.425</td>\n",
              "      <td>1.473</td>\n",
              "      <td>2.425</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.471</td>\n",
              "      <td>0.560</td>\n",
              "      <td>0.471</td>\n",
              "      <td>0.271</td>\n",
              "      <td>0.432</td>\n",
              "      <td>0.271</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2.061</td>\n",
              "      <td>1.354</td>\n",
              "      <td>2.061</td>\n",
              "      <td>1.926</td>\n",
              "      <td>1.307</td>\n",
              "      <td>1.926</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.464</td>\n",
              "      <td>0.560</td>\n",
              "      <td>0.464</td>\n",
              "      <td>0.603</td>\n",
              "      <td>0.637</td>\n",
              "      <td>0.603</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      0     1     2     3     4     5\n",
              "0 2.034 1.343 2.034 2.233 1.431 2.233\n",
              "1 0.205 0.358 0.205 0.150 0.315 0.150\n",
              "2 2.044 1.350 2.044 2.082 1.352 2.082\n",
              "3 0.240 0.358 0.240 0.207 0.345 0.207\n",
              "4 2.069 1.360 2.069 1.850 1.257 1.850\n",
              "5 0.158 0.293 0.158 0.121 0.280 0.121\n",
              "6 2.008 1.337 2.008 2.425 1.473 2.425\n",
              "7 0.471 0.560 0.471 0.271 0.432 0.271\n",
              "8 2.061 1.354 2.061 1.926 1.307 1.926\n",
              "9 0.464 0.560 0.464 0.603 0.637 0.603"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "metadata": {
        "id": "Bd3KBpmN3HwV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**View error trends**"
      ]
    },
    {
      "metadata": {
        "id": "_KoVE-9y3HbY",
        "colab_type": "code",
        "outputId": "851df6f6-c1d6-4973-c88a-97cfc1ba0fce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 705
        }
      },
      "cell_type": "code",
      "source": [
        "def plot_history(history):\n",
        "  hist = pd.DataFrame(history.history)\n",
        "  hist['epoch'] = history.epoch\n",
        "  \n",
        "  plt.figure()\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Mean Abs Error')\n",
        "  plt.plot(hist['epoch'], hist['mean_absolute_error'],\n",
        "           label='Train Error')\n",
        "  plt.plot(hist['epoch'], hist['val_mean_absolute_error'],\n",
        "           label = 'Val Error')\n",
        "  plt.legend()\n",
        "  #plt.ylim([0,3])\n",
        "  \n",
        "  plt.figure()\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Mean Square Error')\n",
        "  plt.plot(hist['epoch'], hist['mean_squared_error'],\n",
        "           label='Train Error')\n",
        "  plt.plot(hist['epoch'], hist['val_mean_squared_error'],\n",
        "           label = 'Val Error')\n",
        "  plt.legend()\n",
        "  #plt.ylim([0,5])\n",
        "\n",
        "plot_history(history)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe8AAAFYCAYAAAB6RnQAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe8AAAFYCAYAAAB6RnQAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "bk13vUm863O3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Assess model performance on test data**"
      ]
    },
    {
      "metadata": {
        "id": "dyieaFiH65NZ",
        "colab_type": "code",
        "outputId": "8541f7d3-4f91-45b1-f321-0bf86bf8211e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "test_features, test_label = process_data(test_dataframe)\n",
        "loss, mae, mse = model.evaluate(test_features, test_label, verbose=0)\n",
        "\n",
        "print(\"Testing set Loss: {:5.2f}\".format(loss))\n",
        "print(\"Testing set Mean Abs Error: {:5.2f}\".format(mae))\n",
        "print(\"Testing set Mean Squared Error: {:5.2f}\".format(mse))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing set Loss:  0.34\n",
            "Testing set Mean Abs Error:  0.23\n",
            "Testing set Mean Squared Error:  0.28\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ZRcQrqi17c3-",
        "colab_type": "code",
        "outputId": "d827aa73-6fd0-4610-8179-f54291db9800",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 378
        }
      },
      "cell_type": "code",
      "source": [
        "test_predictions = model.predict(test_features).flatten()\n",
        "\n",
        "plt.scatter(test_label, test_predictions)\n",
        "plt.xlabel('True Values [delta_6mwt]')\n",
        "plt.ylabel('Predictions [delta_6mwt]')\n",
        "plt.axis('equal')\n",
        "plt.axis('square')\n",
        "plt.xlim([0,plt.xlim()[1]])\n",
        "plt.ylim([0,plt.ylim()[1]])\n",
        "#_ = plt.plot([-100, 100], [-100, 100])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0, 1182.5841960545788)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAASUAAAFYCAYAAAAV2+poAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "eWeDoxc17oEM",
        "colab_type": "code",
        "outputId": "1e8cad06-92b6-4c69-c18e-45f83204c77c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 361
        }
      },
      "cell_type": "code",
      "source": [
        "error = test_predictions - test_labels\n",
        "plt.hist(error, bins = 25)\n",
        "plt.xlabel('Prediction Error ['+target_feature[0]+']')\n",
        "_ = plt.ylabel('Count')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAecAAAFYCAYAAABpkTT0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAGxhJREFUeJzt3Xlw1PX9x/HXJtsINAESXIJytKPl\nkvsIlktqBmgDAhU5EgTrVQ4R0cZiDFhsAdtYaCkghFMYgog4INDhEJHMUA2HRI5QHK4KCWCaSDCB\ngJDw/f3hjy2BZAnJ90s+2TwfM86Q7O738+bjmqffTfJdl2VZlgAAgDECKnoAAABQFHEGAMAwxBkA\nAMMQZwAADEOcAQAwDHEGAMAw7ooe4LqsrDxbjhMaWkM5Ofm2HKuqYy/tw17ah720D3tpn7LspccT\nUuJtfnfm7HYHVvQIfoO9tA97aR/20j7spX3s3ku/izMAAJUdcQYAwDDEGQAAwxBnAAAMQ5wBADAM\ncQYAwDDEGQAAwxBnAAAM42ic169fr/79+2vgwIFKTk52cikAAPyGY3HOycnRO++8o/fee0+JiYna\ntm2bU0sBAOBXHLu2dkpKijp37qzg4GAFBwdrypQpTi0FAIBfcezMOSMjQ5cvX9bo0aM1bNgwpaSk\nOLUUAAB+xdF3pTp//rzmzJmjM2fO6KmnntL27dvlcrmKvW9oaA3bLhzu650+cGfYS/tU1b3sF7uu\n3MfYMGNAkY+r6l46gb20j5176Vic69Spo3bt2sntdqtRo0b68Y9/rHPnzqlOnTrF3t+uty3zeEJs\ne/vJqo69tA97WT437h17aR/20j5l2csKecvIbt26aefOnbp27ZpycnKUn5+v0NBQp5YDAMBvOHbm\nHB4erl/+8pcaMmSIJGnSpEkKCODXqgEAuB1Hv+ccHR2t6OhoJ5cAAMDvcCoLAIBhiDMAAIYhzgAA\nGIY4AwBgGOIMAIBhiDMAAIYhzgAAGIY4AwBgGOIMAIBhiDMAAIYhzgAAGIY4AwBgGOIMAIBhiDMA\nAIYhzgAAGIY4AwBgGOIMAIBhiDMAAIYhzgAAGIY4AwBgGOIMAIBhiDMAAIYhzgAAGIY4AwBgGOIM\nAIBhiDMAAIYhzgAAGIY4AwBgGOIMAIBhiDMAAIYhzgAAGIY4AwBgGOIMAIBhiDMAAIYhzgAAGIY4\nAwBgGOIMAIBhiDMAAIYhzgAAGMbt1IF37dql8ePHq3HjxpKkJk2a6I033nBqOQAA/IZjcZakTp06\nadasWU4uAQCA3+FlbQAADONonI8dO6bRo0crJiZGn332mZNLAQDgN1yWZVlOHDgzM1N79+5VVFSU\n0tPT9dRTT+njjz9WUFBQsfcvKCiU2x3oxChAldYvdl25Hr9hxoAKXd+OGYDKxrHvOYeHh6tPnz6S\npEaNGunee+9VZmamGjZsWOz9c3LybVnX4wlRVlaeLceq6thL+1TmvTRh7htnqMx7aRr20j5l2UuP\nJ6TE2xx7WXv9+vVavHixJCkrK0vffvutwsPDnVoOAAC/4diZc2RkpF599VVt27ZNV69e1Ztvvlni\nS9oAAOB/HItzcHCwEhMTnTo8AAB+i1+lAgDAMMQZAADDEGcAAAxDnAEAMAxxBgDAMMQZAADDEGcA\nAAxDnAEAMAxxBgDAMMQZAADDEGcAAAxDnAEAMAxxBgDAMMQZAADDEGcAAAxDnAEAMAxxBgDAMMQZ\nAADDEGcAAAxDnAEAMAxxBgDAMMQZAADDEGcAAAxDnAEAMAxxBgDAMMQZAADDEGcAAAxDnAEAMAxx\nBgDAMMQZAADDEGcAAAxDnAEAMAxxBgDAMMQZAADDEGcAAAxDnAEAMAxxBgDAMMQZAADDOBrny5cv\nq2fPnlqzZo2TywAA4FccjfO8efNUq1YtJ5cAAMDvOBbn48eP69ixY/rFL37h1BIAAPglx+KckJCg\nuLg4pw4PAIDfcjtx0I8++kht27ZVw4YNS/2Y0NAacrsDbVnf4wmx5Tgo/172i11XrsdvmDGgUq9/\no8r6vDRh7ptnuNOZTHoemMaEf7/+ws69dCTOycnJSk9PV3Jysr755hsFBQWpXr166tKlS4mPycnJ\nt2VtjydEWVl5thyrqjNhL/1lfRP2sqxMmPvGGSpiL03YAydU5uelacqyl75i7kicZ86c6f3z7Nmz\nVb9+fZ9hBgAA/8PvOQMAYBhHzpxvNG7cOKeXAADAr3DmDACAYYgzAACGIc4AABiGOAMAYBjiDACA\nYYgzAACGIc4AABiGOAMAYBjiDACAYYgzAACGIc4AABiGOAMAYBjiDACAYYgzAACGIc4AABiGOAMA\nYBjiDACAYYgzAACGIc4AABiGOAMAYBjiDACAYYgzAACGKVWcjx8/fsvn9u3bZ/swAADgNnHOzc3V\nqVOnFB8fr/T0dO8/J06c0GuvvXa3ZgQAoEpx+7rxyy+/1LJly3T48GH95je/8X4+ICBA3bp1c3w4\nAACqIp9x7tGjh3r06KGVK1cqJibmbs0EAECV5jPO1/Xs2VPLli3Td999J8uyvJ8fP368Y4MBAFBV\nleoHwkaNGqWvvvpKAQEBCgwM9P4DAADsV6oz5xo1aujPf/6z07MAAACV8sy5TZs2xf46FQAAsF+p\nzpx37NihpUuXKjQ0VG63W5ZlyeVyKTk52eHxAACoekoV53nz5jk9BwAA+H+linNKSkqxnx80aJCt\nwwAAgFLGee/evd4/X7lyRQcOHFD79u2JMwAADihVnG/+Se1Lly7p9ddfd2QgAACqujK9K1X16tV1\n6tQpu2cBAAAq5ZnzsGHD5HK5vB9nZmaqadOmjg0FAEBVVqo4v/zyy94/u1wuBQcHq1mzZo4NBQBA\nVVaql7U7deqkgIAAHTp0SIcOHdLly5eLnEkDAAD7lOrM+R//+Ic+++wzdejQQZI0depU9e7dW6NG\njSrxMZcuXVJcXJy+/fZbff/993rhhRf06KOP2jM1AAB+rFRx3rVrl95//30FBPxwol1QUKDhw4f7\njPP27dvVsmVL/fa3v9Xp06f17LPPEmcAAEqhVHG+du2aN8yS5Ha7b/uydp8+fbx/Pnv2rMLDw8s4\nIgAAVUup4tyyZUuNHj1aXbp0kSR9/vnnatmyZakWiI6O1jfffKPExESf9wsNrSG32563ofR4Qmw5\nDip+Lyv7+v1i15V7hg0zBpT7GOVR0f8Oipvhbs9kwh44xZ//bnebnXt52zinp6crPj5emzZt0v79\n++VyudSxY0c9//zzpVrg/fff1+HDh/X73/9e69evL/GMOycn/84mL4HHE6KsrDxbjlXVmbCXVX19\nE2ao6PVvnqEinpcm7IETTPhv3F+UZS99xdznT2unpKQoJiZGFy9eVN++fRUfH6+BAwdq5cqVSktL\n87loWlqazp49K0lq3ry5CgsLde7cuTsaHACAqshnnOfMmaMlS5YoJOR/dW/atKkSExM1c+ZMnwf+\n4osvtGTJEklSdna28vPzFRoaasPIAAD4N59xtixLTZo0ueXzjRs31vfff+/zwNHR0Tp37pyGDRum\nkSNH6g9/+EORHyoDAADF8/k95/z8kr8PfP78eZ8HrlatmmbMmFG2qQAAqMJ8nso2btxYK1euvOXz\nCxcuVJs2bRwbCgCAqsznmfOECRM0duxYrVu3Ti1bttS1a9eUmpqq4OBgzZ8//27NCABAleIzzh6P\nRx988IFSUlJ09OhRBQYGKioqShEREXdrPgAAqpxSXYSkc+fO6ty5s9OzAAAAlfJdqQAAwN1DnAEA\nMAxxBgDAMMQZAADDEGcAAAxDnAEAMAxxBgDAMMQZAADDEGcAAAxDnAEAMAxxBgDAMMQZAADDEGcA\nAAxDnAEAMAxxBgDAMMQZAADDEGcAAAxDnAEAMAxxBgDAMMQZAADDEGcAAAxDnAEAMAxxBgDAMMQZ\nAADDEGcAAAxDnAEAMAxxBgDAMMQZAADDEGcAAAxDnAEAMAxxBgDAMMQZAADDEGcAAAxDnAEAMIzb\nyYO//fbb2rt3rwoKCjRq1Cj17t3byeUAAPALjsV5586dOnr0qFatWqWcnBw9/vjjxBkAgFJwLM4R\nERFq3bq1JKlmzZq6dOmSCgsLFRgY6NSSAAD4Bce+5xwYGKgaNWpIkj788EM98sgjhBkAgFJwWZZl\nObnAJ598ovnz52vJkiUKCQkp8X4FBYVyu+2Ld7/YdeV6/IYZA2yapOKYsAflnQHwB/7w9aS8TPh6\nVJk4+gNhO3bsUGJiohYtWuQzzJKUk5Nvy5oeT4iysvLKfRw7juEP2Aeg/Ez978iur5d3g+lzlmUv\nPZ6Su+hYnPPy8vT2229r6dKlql27tlPLAADgdxyL88aNG5WTk6OXX37Z+7mEhATdf//9Ti0JAIBf\ncCzOQ4cO1dChQ506PAAAfosrhAEAYBjiDACAYYgzAACGIc4AABiGOAMAYBjiDACAYYgzAACGIc4A\nABiGOAMAYBjiDACAYYgzAACGIc4AABiGOAMAYBjiDACAYYgzAACGIc4AABiGOAMAYBjiDACAYYgz\nAACGIc4AABiGOAMAYBjiDACAYYgzAACGIc4AABiGOAMAYBjiDACAYYgzAACGIc4AABiGOAMAYBji\nDACAYYgzAACGIc4AABiGOAMAYBjiDACAYYgzAACGIc4AABiGOAMAYBjiDACAYYgzAACGcTTOR44c\nUc+ePZWUlOTkMgAA+BXH4pyfn68pU6aoc+fOTi0BAIBfcizOQUFBWrhwoerWrevUEgAA+CW3Ywd2\nu+V2l/7woaE15HYH2rK2xxNixDH6xa4r9zEqUmWfHzCFHV9PnGLybDcy4WvyhhkDfN5u5146Fuc7\nlZOTb8txPJ4QZWXllfs4dhwDACRzv57Y9fXybjBhTl8zlGUvfcWcn9YGAMAwxBkAAMM49rJ2Wlqa\nEhISdPr0abndbm3ZskWzZ89W7dq1nVoSAAC/4FicW7ZsqeXLlzt1eAAA/BYvawMAYBjiDACAYYgz\nAACGIc4AABiGOAMAYBjiDACAYYgzAACGIc4AABiGOAMAYBjiDACAYYgzAACGIc4AABiGOAMAYBji\nDACAYYgzAACGIc4AABiGOAMAYBjiDACAYYgzAACGIc4AABiGOAMAYBjiDACAYYgzAACGIc4AABiG\nOAMAYBjiDACAYYgzAACGIc4AABiGOAMAYBjiDACAYYgzAACGIc4AABiGOAMAYBjiDACAYYgzAACG\nIc4AABiGOAMAYBjiDACAYdxOHvytt97S/v375XK5FB8fr9atWzu5HAAAfsGxOO/evVsnT57UqlWr\ndPz4ccXHx2vVqlVOLQcAgN9w7GXtlJQU9ezZU5L04IMP6rvvvtOFCxecWg4AAL/hWJyzs7MVGhrq\n/TgsLExZWVlOLQcAgN9w9HvON7Isy+ftHk+IbWt5PCHaMGOAbccrKxNmAABf7Pza64sJXw+dnsHO\nvXTszLlu3brKzs72fvzf//5XHo/HqeUAAPAbjsW5a9eu2rJliyTp0KFDqlu3roKDg51aDgAAv+HY\ny9rt27dXixYtFB0dLZfLpcmTJzu1FAAAfsVl3e6bwQAA4K7iCmEAABiGOAMAYJhKH+fdu3erc+fO\n2r59e7G3r1+/Xk888YQGDx6s1atX3+XpKo+rV68qNjZWMTExGj58uNLT02+5T4sWLTRixAjvP4WF\nhRUwqdneeustDR06VNHR0Tpw4ECR2z7//HMNGjRIQ4cO1TvvvFNBE1YevvYyMjJSw4YN8z4XMzMz\nK2jKyuPIkSPq2bOnkpKSbrmN5+ad8bWXtj03rUrs5MmT1ujRo60XXnjB+vTTT2+5/eLFi1bv3r2t\n3Nxc69KlS1bfvn2tnJycCpjUfGvWrLHefPNNy7Isa8eOHdb48eNvuU+nTp3u9liVyq5du6yRI0da\nlmVZx44ds4YMGVLk9qioKOvMmTNWYWGhFRMTYx09erQixqwUbreXjz76qHXhwoWKGK1SunjxojV8\n+HBr0qRJ1vLly2+5nedm6d1uL+16blbqM2ePx6M5c+YoJKT4X/zev3+/WrVqpZCQEFWrVk3t27dX\namrqXZ6yckhJSVGvXr0kSV26dGGfysDXJWvT09NVq1Yt3XfffQoICFCPHj2UkpJSkeMajcv/2iso\nKEgLFy5U3bp1b7mN5+ad8bWXdqrUca5evboCAwNLvD07O1thYWHej7mEaMlu3KuAgAC5XC5duXKl\nyH2uXLmi2NhYRUdH6913362IMY3m65K1WVlZPBfvQGku/zt58mTFxMRo+vTpt70CYVXndrtVrVq1\nYm/juXlnfO3ldXY8N+/a5TvLa/Xq1bd8z3jcuHHq3r17qY/Bf8A/KG4v9+/fX+Tj4vZqwoQJ6t+/\nv1wul4YPH66OHTuqVatWjs5amfF8s8/Ne/nSSy+pe/fuqlWrlsaOHastW7boV7/6VQVNB/yPXc/N\nShPnwYMHa/DgwXf0mOIuIdq2bVu7R6t0itvLuLg4ZWVlqVmzZrp69aosy1JQUFCR+8TExHj//POf\n/1xHjhwhzjfwdcnam2/LzMx0/GWxyux2l//99a9/7f3zI488oiNHjhDnMuK5aS+7npuV+mXt22nT\npo0OHjyo3NxcXbx4UampqerYsWNFj2Wkrl27avPmzZKk7du36+GHHy5y+4kTJxQbGyvLslRQUKDU\n1FQ1bty4IkY1lq9L1jZo0EAXLlxQRkaGCgoKtH37dnXt2rUixzWar73My8vTc8895/22y549e3gu\nlgPPTfvY+dys1FcIS05O1uLFi3XixAmFhYXJ4/FoyZIlWrBggSIiItSuXTtt3rxZixcv9r4U279/\n/4oe20iFhYWaNGmSvv76awUFBekvf/mL7rvvviJ7+de//lU7d+5UQECAIiMjNWbMmIoe2zjTp0/X\nF1984b1k7b///W+FhISoV69e2rNnj6ZPny5J6t27t5577rkKntZsvvZy2bJl+uijj3TPPffooYce\n0htvvCGXy1XRIxsrLS1NCQkJOn36tNxut8LDwxUZGakGDRrw3LxDt9tLu56blTrOAAD4I79+WRsA\ngMqIOAMAYBjiDACAYYgzAACGIc4AABiGOKPKycjIUMuWLb3vGhMdHa3Y2Fjl5uaW+ZirV69WXFyc\nJOmVV17x+U40qamp3nf9mjZtmtLS0sq87nWRkZEaPHhwkXcNi42NLfdxi7NmzRpFRkZq2rRpZXr8\nhg0bdO3aNZununPr1q2T9MO/g8jISK1Zs6aCJwL+p9JcIQywU1hYmJYvX+79OCEhQfPmzdNrr71W\n7mP//e9/93n7mjVr1KdPHzVs2FATJ04s93rXTZ8+XT/5yU9sO54vjz/+uMaNG1emx86ePVtRUVEK\nCKi4c4PCwkLNnTtXAwYM0MSJE1WzZs0KmwUoDnEGJEVERGjVqlWSfjgLjYqKUnp6umbNmqWNGzcq\nKSlJlmUpLCxMU6dOVWhoqFasWKGVK1eqXr16RS53GBkZqXfffVcNGzbU1KlTvWfGzzzzjNxutzZv\n3qwDBw7o9ddf19y5czVmzBh16dJFc+fOVXJystxutxo3bqxJkyYpMzNTY8aMUbdu3XTgwAFdvHhR\n8+fPV3h4eKn/biNGjFCzZs10+PBhLVu2TBERERo0aJCuXbumSZMm+Vy3SZMmaty4sUaPHl3i8f/2\nt78pNTVVly9fVkREhCZMmKDdu3drwYIFqlevno4dOya3261FixZp4cKFOnnypJ5++mnNmTNHkZGR\n3lnS0tL0yiuveK9O9/zzz2vEiBHq0aNHsevGxcUpNDRUx48f17FjxxQbG6tPP/1UR44cUfv27fXH\nP/6xxPni4+N1+vRpPfvss1qyZEmp9xK4W3hZG1VeYWGhtm7dqg4dOng/99Of/lSzZs3S2bNnlZiY\nqKVLl2rlypXq1KmT5s+fr7y8PM2aNUvLly/XokWLlJOTc8tx169fr+zsbH3wwQdatGiR1q5dq8jI\nSDVv3lxxcXHq3Lmz975ffvmlPv74Y61YsULvvfeecnJy9M9//lOSdPz4cQ0cOFArVqxQ8+bNtWnT\npjv+O9aoUUNJSUkKDAxUfn6+evTooUmTJt123bFjx/oM86ZNm5SZmamkpCR9+OGHOnXqlLZv3y5J\n2rdvn373u99p1apVCggI0L/+9S+99NJLkqSlS5eqdu3aRWaJjo7W2rVrJUnnz5/Xf/7zn9u+sU12\ndrYWLFigF198UX/60580efJkrV69WmvXrlVubm6J840bN05hYWGEGcbizBlV0rlz5zRixAhJ0rVr\n19SxY0c9/fTT3tvbtWsn6YdoZmVleS9neOXKFTVo0EAnT55U/fr1vW9r+PDDD+urr74qssaBAwe8\nZ4E1a9bUggULSpxn//79ioiI0I9+9CNJUqdOnXTw4EFFREQoNDTUe33e+++/X+fPny/2GK+++mqR\nt7J77LHHNHToUElS+/btvZ+3LMv7sa91a9WqpQceeKDEmSVp165d2rdvn3cv8/LylJGRoaZNm+rB\nBx9UnTp1JEn169cvdu4bZ4mKitLMmTN18eJFbd26Vf369bvtS9/XH1uvXj098MAD3pena9eurby8\nvBLna9Kkic/jAhWNOKNKuvl7zje7HqugoCC1bt1a8+fPL3L7wYMHi1wvt7gfcHK5XKX+waebr71r\nWZb3cze/Z3lJV9z19T3n63+fmz/2te7NjylOUFCQhgwZcsu1mHft2uXzvdaLm+Wee+5Rr169tHXr\nVm3ZskWTJ0++7WPdbnexf5bkfWe14ubLyMgo1WxAReFlbcCHVq1a6cCBA943n9+0aZM++eQTNWrU\nSBkZGcrNzZVlWUpJSbnlse3atdOOHTskSRcuXNDgwYN15coVuVwuXb16tch927Ztq127dnk/n5KS\nojZt2jj8tyv/uh06dNDWrVtVUFAgSZozZ46+/vprn49xuVze+99s6NChWrlypSzLUsOGDUs9x53O\nFxAQUOIMgAk4cwZ8CA8P18SJEzVq1ChVr15d1apVU0JCgmrVqqXRo0frySefVP369VW/fn1dvny5\nyGOjoqKUmpqq6OhoFRYW6plnnlFQUJC6du2qyZMnKz4+3nvfNm3aqG/fvnryyScVEBCgFi1a6LHH\nHtOZM2dKPevNL2tL0ty5c30+przr9u7dW/v27VN0dLQCAwP10EMPqWHDhj5/lax79+564oknNG/e\nvFtu+9nPfqbCwkINHDiwVOuXdT7LsnTvvfdq4MCBSkpKsmUtwE68KxWAO7JmzRqdPn26zL9K5UtG\nRoZGjhypdevWlepldbvMnj1b9evXt+1/CoDy4swZwB27/tPQdv6edmJiojZu3KgpU6Z4wzxr1izt\n2bPnlvs2a9bMtrWnTZumbdu26cUXX7TleIAdOHMGAMAw/EAYAACGIc4AABiGOAMAYBjiDACAYYgz\nAACGIc4AABjm/wCsQ1DXuXqoEwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}